{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52fcc20",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd, itertools\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, utils\n",
    "\n",
    "# Configure plotly to use static rendering if widgets fail\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "float_formatter = \"{:.5f}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15f0d1",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1437fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf],\n",
      "        [0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf],\n",
      "        [-inf, -inf, 0., -inf, -inf],\n",
      "        [-inf, -inf, 0., 0., -inf]])\n"
     ]
    }
   ],
   "source": [
    "# ---------- constants ----------\n",
    "LIST_LEN = 2 # [d1, d2]\n",
    "SEQ_LEN = LIST_LEN * 2 + 1 # [d1, d2, SEP, o1, o2]\n",
    "\n",
    "N_DIGITS = 100\n",
    "DIGITS = list(range(N_DIGITS)) # 100 digits from 0 to 99\n",
    "SEP = DIGITS[-1] + 1 # special seperator token for the model to think about the input (+1 to avoid confusion with the last digit)\n",
    "VOCAB = len(DIGITS) + 1  # +1 for the special token\n",
    "\n",
    "D_MODEL = 8\n",
    "N_HEAD = 1 # 1\n",
    "N_LAYER = 3 # 2\n",
    "USE_LN = False # use layer norm in model\n",
    "USE_BIAS = False # use bias in model\n",
    "FREEZE_WV = True # no value matrix in attn \n",
    "FREEZE_WO = True # no output matrix in attn (i.e. attn head can only copy inputs to outputs)\n",
    "WEIGHT_DECAY = 0.01 # default 0.01\n",
    "\n",
    "TRAIN_SPLIT = 0.8 # 80% train, 20% test\n",
    "MAX_TRAIN_STEPS = 300_000 # max training steps\n",
    "\n",
    "# model name for saving and loading\n",
    "# MODEL_NAME = f'{N_DIGITS}dig_{D_MODEL}d'\n",
    "MODEL_NAME = '3layer_100dig_8d'\n",
    "MODEL_PATH = \"models/\" + MODEL_NAME + \".pt\"\n",
    "\n",
    "USE_CHECKPOINTING = True # whether to use checkpointing for training\n",
    "\n",
    "DEV = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "device = DEV\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ---------- mask ----------\n",
    "# attention mask for [d1, d2, SEP, o1, o2] looks like this (query rows are horizontal, key columns are vertical):\n",
    "# -    d1    d2    SEP    o1    o2   (keys)\n",
    "# d1  -inf  -inf   -inf  -inf  -inf\n",
    "# d2   0    -inf   -inf  -inf  -inf\n",
    "# SEP  0      0    -inf  -inf  -inf\n",
    "# o1  -inf  -inf    0    -inf   -inf\n",
    "# o2  -inf  -inf    0      0    -inf\n",
    "# (queries)\n",
    "\n",
    "mask_bias = torch.triu(torch.ones(SEQ_LEN, SEQ_LEN) * float(\"-inf\")) # upper triangular bias mask (lead_diag & above = -inf, rest = 0)\n",
    "mask_bias[0, 0] = 0. #Â don't want a full row of -inf! otherwise we get nan erros & training breaks\n",
    "mask_bias[LIST_LEN+1:, :LIST_LEN] = float(\"-inf\") # stop output tokens from attending to input tokens\n",
    "mask_bias = mask_bias.unsqueeze(0).unsqueeze(0) # (1,1,T,T) broadcastable across batch and heads\n",
    "\n",
    "print(mask_bias.cpu()[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a60abc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([ 60,  44, 100, 100, 100])\n",
      "Target: tensor([ 60,  44, 100,  60,  44])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8000, 2000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- data ----------\n",
    "# Create all possible combinations of digits\n",
    "all_data = list(itertools.product(DIGITS, repeat=LIST_LEN))\n",
    "n_data = len(all_data)\n",
    "all_data = torch.tensor(all_data, dtype=torch.int64)\n",
    "\n",
    "# Create sequences of the form [d1, d2, SEP, d1, d2]\n",
    "all_targets = torch.full((n_data, SEQ_LEN), SEP)\n",
    "all_targets[:, :LIST_LEN] = all_data\n",
    "all_targets[:, LIST_LEN+1:] = all_data\n",
    "\n",
    "# Create input sequences of the form [d1, d2, SEP, SEP, SEP]\n",
    "all_inputs = all_targets.clone()\n",
    "all_inputs[:, LIST_LEN+1:] = SEP\n",
    "\n",
    "# Shuffle the dataset (inputs and targets together)\n",
    "perm = torch.randperm(n_data)\n",
    "all_inputs = all_inputs[perm]\n",
    "all_targets = all_targets[perm]\n",
    "\n",
    "train_ds = TensorDataset(all_inputs[:int(TRAIN_SPLIT*n_data)], all_targets[:int(TRAIN_SPLIT*n_data)])  # 80% for training\n",
    "val_ds = TensorDataset(all_inputs[int(TRAIN_SPLIT*n_data):], all_targets[int(TRAIN_SPLIT*n_data):])  # 20% for validation\n",
    "train_batch_size = min(128, len(train_ds))  # Use a batch size of 128 or less if dataset is smaller\n",
    "val_batch_size = min(256, len(val_ds))  # Use a batch size of 256 or less if dataset is smaller\n",
    "train_dl = DataLoader(train_ds, train_batch_size, shuffle=True, drop_last=True)\n",
    "val_dl = DataLoader(val_ds, val_batch_size, drop_last=False)\n",
    "\n",
    "print(\"Input:\", train_ds[0][0])  # Example input: [d1, d2, SEP, SEP, SEP]\n",
    "print(\"Target:\", train_ds[0][1]) # Example target: [d1, d2, SEP, d1, d2]\n",
    "len(train_ds), len(val_ds)  # Should be 80% for train and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7dbed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- config helper ----------\n",
    "def attach_custom_mask(model):\n",
    "    def _mask(scores, hook=None):\n",
    "        # scores: (batch, heads, Q, K)\n",
    "        return scores + mask_bias.to(scores.device)\n",
    "    \n",
    "    # register the same mask hook on every layer\n",
    "    for block in model.blocks:\n",
    "        block.attn.hook_attn_scores.add_perma_hook(_mask, dir=\"fwd\")\n",
    "\n",
    "\n",
    "def strip_bias(m):\n",
    "    for mod in m.modules():\n",
    "        if hasattr(mod, \"bias\") and mod.bias is not None:\n",
    "            mod.bias.requires_grad_(False)\n",
    "            torch.nn.init.zeros_(mod.bias)\n",
    "            print(mod)\n",
    "\n",
    "    # remove biases from attention layers\n",
    "    attn_biases = ['b_Q', 'b_K', 'b_V', 'b_O']\n",
    "    for block in m.blocks:\n",
    "        for b in attn_biases:\n",
    "            mod = getattr(block.attn, b, None)\n",
    "            if mod is not None:\n",
    "                mod.requires_grad_(False)\n",
    "                torch.nn.init.zeros_(mod)\n",
    "\n",
    "    # remove unembed bias\n",
    "    if hasattr(m, \"unembed\") and m.b_U is not None:\n",
    "        m.unembed.b_U.requires_grad_(False)\n",
    "        torch.nn.init.zeros_(m.unembed.b_U)\n",
    "\n",
    "def set_WV_identity_and_freeze(model, d_model):\n",
    "    with torch.no_grad():\n",
    "        # Create a stack of identity-like matrices for W_V\n",
    "        # Each matrix is of shape (d_model, d_head)\n",
    "        # We take the first d_head columns of the d_model x d_model identity matrix\n",
    "        identity_slice = torch.eye(d_model, model.cfg.d_head)\n",
    "        # Repeat for each head\n",
    "        W_V_identity = identity_slice.unsqueeze(0).repeat(model.cfg.n_heads, 1, 1)\n",
    "        \n",
    "        for block in model.blocks:\n",
    "            block.attn.W_V.copy_(W_V_identity)\n",
    "            block.attn.W_V.requires_grad = False\n",
    "\n",
    "def set_WO_identity_and_freeze(model, d_model):\n",
    "    with torch.no_grad():\n",
    "        # Create a stack of identity-like matrices for W_O\n",
    "        # Each matrix is of shape (d_head, d_model)\n",
    "        # We take the first d_head rows of the d_model x d_model identity matrix\n",
    "        identity_slice = torch.eye(model.cfg.d_head, d_model)\n",
    "        # Repeat for each head\n",
    "        W_O_identity = identity_slice.unsqueeze(0).repeat(model.cfg.n_heads, 1, 1)\n",
    "\n",
    "        for block in model.blocks:\n",
    "            block.attn.W_O.copy_(W_O_identity)\n",
    "            block.attn.W_O.requires_grad = False\n",
    "\n",
    "\n",
    "def make_model(n_layers=N_LAYER, n_heads=N_HEAD, d_model=D_MODEL, ln=USE_LN, use_bias=USE_BIAS, freeze_wv=FREEZE_WV, freeze_wo=FREEZE_WO):\n",
    "    cfg = HookedTransformerConfig(\n",
    "        n_layers = n_layers,\n",
    "        n_heads = n_heads,\n",
    "        d_model = d_model,\n",
    "        d_head = d_model//n_heads,\n",
    "        n_ctx=SEQ_LEN,\n",
    "        d_vocab=VOCAB,\n",
    "        attn_only=True, # no MLP!\n",
    "        normalization_type=(\"LN\" if ln else None),\n",
    "    )\n",
    "    model = HookedTransformer(cfg).to(DEV)\n",
    "    if freeze_wv:\n",
    "        set_WV_identity_and_freeze(model, d_model)\n",
    "    if freeze_wo:\n",
    "        set_WO_identity_and_freeze(model, d_model)\n",
    "    if not use_bias:\n",
    "        strip_bias(model)\n",
    "    \n",
    "    attach_custom_mask(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e326dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Model saving / loading helpers ------\n",
    "def save_model(model, path = MODEL_PATH):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def load_model(path = MODEL_PATH, device = DEV):\n",
    "    print(\"Loading model from\", path)\n",
    "    model = make_model()\n",
    "    model.load_state_dict(\n",
    "        torch.load(path, map_location=device)\n",
    "    )  # map weights to target device\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95071794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- utilities ----------\n",
    "def accuracy(m):\n",
    "    m.eval()\n",
    "    hits = tots = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_dl:\n",
    "            logits = m(inputs.to(DEV))[:, LIST_LEN+1:]  # (batch, 2, vocab)\n",
    "            preds = logits.argmax(-1)\n",
    "            hits += (preds == targets[:, LIST_LEN+1:].to(DEV)).sum().item()\n",
    "            tots += preds.numel()\n",
    "    return hits / tots\n",
    "\n",
    "\n",
    "def train(m, max_steps=10_000, early_stop_acc=0.999, checkpoints=False, weight_decay=WEIGHT_DECAY, verbose=True):\n",
    "    opt = torch.optim.AdamW(m.parameters(), 1e-3, weight_decay=weight_decay)\n",
    "    ce = torch.nn.CrossEntropyLoss()\n",
    "    dl = itertools.cycle(train_dl)  # infinite iterator\n",
    "    for step in tqdm(range(max_steps), desc=\"Training\"):\n",
    "        inputs, targets = next(dl)\n",
    "        # get logits/loss for output tokens only\n",
    "        logits = m(inputs.to(DEV))[:, LIST_LEN+1:].reshape(-1, VOCAB) \n",
    "        loss = ce(logits, targets[:, LIST_LEN+1:].reshape(-1).to(DEV))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        if (step + 1) % 100 == 0:\n",
    "            acc = accuracy(m)\n",
    "            if acc >= early_stop_acc:\n",
    "                print(f\"Early stopping at step {step + 1} with accuracy {acc:.2%} >= {early_stop_acc:.2%}\")\n",
    "                break\n",
    "            update_every = max(min(10_000, 0.05*max_steps), 1000)\n",
    "            if verbose and (step+1) % update_every == 0:\n",
    "                print(f\"Step {step + 1}, Loss: {loss.item():.4f}, Accuracy: {acc:.2%}\")\n",
    "            if checkpoints and (step+1) % 50_000 == 0:\n",
    "                save_model(m, MODEL_PATH)\n",
    "            \n",
    "    print(f\"Final accuracy: {accuracy(m):.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea857e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 60,  44, 100, 100, 100],\n",
       "         [ 28,  90, 100, 100, 100],\n",
       "         [ 93,  99, 100, 100, 100],\n",
       "         [ 19,  17, 100, 100, 100],\n",
       "         [ 49,  19, 100, 100, 100]]),\n",
       " tensor([[ 60,  44, 100,  60,  44],\n",
       "         [ 28,  90, 100,  28,  90],\n",
       "         [ 93,  99, 100,  93,  99],\n",
       "         [ 19,  17, 100,  19,  17],\n",
       "         [ 49,  19, 100,  49,  19]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check train set\n",
    "train_ds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training model: d128_2L_noLN_noBias_uWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd87e28785d044a4a325d92c02da9b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.7330, Accuracy: 48.40%\n",
      "Step 5000, Loss: 0.7325, Accuracy: 47.77%\n",
      "Step 7500, Loss: 0.7095, Accuracy: 48.33%\n",
      "Step 10000, Loss: 0.7193, Accuracy: 48.27%\n",
      "Step 12500, Loss: 0.7161, Accuracy: 47.93%\n",
      "Step 15000, Loss: 0.7122, Accuracy: 47.70%\n",
      "Step 17500, Loss: 0.7111, Accuracy: 47.83%\n",
      "Step 20000, Loss: 0.6909, Accuracy: 47.33%\n",
      "Step 22500, Loss: 0.6990, Accuracy: 47.35%\n",
      "Step 25000, Loss: 0.6969, Accuracy: 48.45%\n",
      "Step 27500, Loss: 0.7198, Accuracy: 47.27%\n",
      "Step 30000, Loss: 0.7127, Accuracy: 47.17%\n",
      "Step 32500, Loss: 0.7063, Accuracy: 47.08%\n",
      "Step 35000, Loss: 0.6831, Accuracy: 46.60%\n",
      "Step 37500, Loss: 0.7150, Accuracy: 47.38%\n",
      "Step 40000, Loss: 0.7102, Accuracy: 47.02%\n",
      "Step 42500, Loss: 0.6986, Accuracy: 47.12%\n",
      "Step 45000, Loss: 0.6993, Accuracy: 46.48%\n",
      "Step 47500, Loss: 0.7272, Accuracy: 46.77%\n",
      "Step 50000, Loss: 0.7146, Accuracy: 46.25%\n",
      "Final accuracy: 46.25%\n",
      "--- Training model: d128_2L_noLN_noBias_uWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8cfe9aaa4e4c0b90a104f58f62cc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.7057, Accuracy: 47.73%\n",
      "Step 5000, Loss: 0.7009, Accuracy: 47.62%\n",
      "Step 7500, Loss: 0.6937, Accuracy: 47.10%\n",
      "Step 10000, Loss: 0.6927, Accuracy: 46.77%\n",
      "Step 12500, Loss: 0.6991, Accuracy: 47.00%\n",
      "Step 15000, Loss: 0.6852, Accuracy: 46.23%\n",
      "Step 17500, Loss: 0.7053, Accuracy: 46.58%\n",
      "Step 20000, Loss: 0.6888, Accuracy: 46.88%\n",
      "Step 22500, Loss: 0.6815, Accuracy: 46.65%\n",
      "Step 25000, Loss: 0.6974, Accuracy: 46.88%\n",
      "Step 27500, Loss: 0.6881, Accuracy: 47.40%\n",
      "Step 30000, Loss: 0.6892, Accuracy: 46.65%\n",
      "Step 32500, Loss: 0.6811, Accuracy: 46.52%\n",
      "Step 35000, Loss: 0.7078, Accuracy: 46.23%\n",
      "Step 37500, Loss: 0.6839, Accuracy: 46.25%\n",
      "Step 40000, Loss: 0.6875, Accuracy: 46.27%\n",
      "Step 42500, Loss: 0.6727, Accuracy: 46.42%\n",
      "Step 45000, Loss: 0.6999, Accuracy: 47.38%\n",
      "Step 47500, Loss: 0.6684, Accuracy: 45.67%\n",
      "Step 50000, Loss: 0.7015, Accuracy: 48.95%\n",
      "Final accuracy: 48.95%\n",
      "--- Training model: d128_2L_noLN_noBias_fWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8403be3f17d342f89450e17eeb3c2b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.6987, Accuracy: 47.77%\n",
      "Step 5000, Loss: 0.6949, Accuracy: 47.30%\n",
      "Step 7500, Loss: 0.6973, Accuracy: 47.42%\n",
      "Step 10000, Loss: 0.6991, Accuracy: 47.10%\n",
      "Step 12500, Loss: 0.6919, Accuracy: 46.83%\n",
      "Step 15000, Loss: 0.6870, Accuracy: 46.45%\n",
      "Step 17500, Loss: 0.6872, Accuracy: 46.52%\n",
      "Step 20000, Loss: 0.7107, Accuracy: 47.40%\n",
      "Step 22500, Loss: 0.6978, Accuracy: 46.05%\n",
      "Step 25000, Loss: 0.6946, Accuracy: 47.38%\n",
      "Step 27500, Loss: 0.6928, Accuracy: 47.05%\n",
      "Step 30000, Loss: 0.6888, Accuracy: 47.48%\n",
      "Step 32500, Loss: 0.6975, Accuracy: 47.12%\n",
      "Step 35000, Loss: 0.6965, Accuracy: 47.02%\n",
      "Step 37500, Loss: 0.6908, Accuracy: 47.23%\n",
      "Step 40000, Loss: 0.6989, Accuracy: 46.35%\n",
      "Step 42500, Loss: 0.6743, Accuracy: 47.02%\n",
      "Step 45000, Loss: 0.6945, Accuracy: 46.77%\n",
      "Step 47500, Loss: 0.6898, Accuracy: 46.02%\n",
      "Step 50000, Loss: 0.6979, Accuracy: 46.30%\n",
      "Final accuracy: 46.30%\n",
      "--- Training model: d128_2L_noLN_noBias_fWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54372d7c6f6d4004add1578099195cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.6906, Accuracy: 43.88%\n",
      "Step 5000, Loss: 0.6850, Accuracy: 46.05%\n",
      "Step 7500, Loss: 0.6943, Accuracy: 44.12%\n",
      "Step 10000, Loss: 0.6844, Accuracy: 44.35%\n",
      "Step 12500, Loss: 0.6875, Accuracy: 43.68%\n",
      "Step 15000, Loss: 0.6860, Accuracy: 44.77%\n",
      "Step 17500, Loss: 0.6369, Accuracy: 45.90%\n",
      "Step 20000, Loss: 0.6764, Accuracy: 44.25%\n",
      "Step 22500, Loss: 0.6808, Accuracy: 44.25%\n",
      "Step 25000, Loss: 0.6866, Accuracy: 44.27%\n",
      "Step 27500, Loss: 0.6631, Accuracy: 44.50%\n",
      "Step 30000, Loss: 0.3340, Accuracy: 84.45%\n",
      "Step 32500, Loss: 0.2394, Accuracy: 87.30%\n",
      "Step 35000, Loss: 0.1735, Accuracy: 89.62%\n",
      "Step 37500, Loss: 0.1456, Accuracy: 90.18%\n",
      "Step 40000, Loss: 0.1193, Accuracy: 90.95%\n",
      "Step 42500, Loss: 0.1048, Accuracy: 90.95%\n",
      "Step 45000, Loss: 0.0786, Accuracy: 91.00%\n",
      "Step 47500, Loss: 0.0796, Accuracy: 91.25%\n",
      "Step 50000, Loss: 0.0970, Accuracy: 91.72%\n",
      "Final accuracy: 91.72%\n",
      "--- Training model: d128_2L_noLN_Bias_uWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9399e497e3f849798becbbec4175bfc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.7224, Accuracy: 48.60%\n",
      "Step 5000, Loss: 0.7144, Accuracy: 47.95%\n",
      "Step 7500, Loss: 0.7345, Accuracy: 47.67%\n",
      "Step 10000, Loss: 0.7161, Accuracy: 47.48%\n",
      "Step 12500, Loss: 0.7216, Accuracy: 48.05%\n",
      "Step 15000, Loss: 0.7224, Accuracy: 47.20%\n",
      "Step 17500, Loss: 0.6926, Accuracy: 46.77%\n",
      "Step 20000, Loss: 0.7084, Accuracy: 47.42%\n",
      "Step 22500, Loss: 0.1840, Accuracy: 84.70%\n",
      "Step 25000, Loss: 0.3053, Accuracy: 80.20%\n",
      "Step 27500, Loss: 0.1903, Accuracy: 85.17%\n",
      "Step 30000, Loss: 0.1579, Accuracy: 87.17%\n",
      "Step 32500, Loss: 0.1527, Accuracy: 86.72%\n",
      "Step 35000, Loss: 0.1315, Accuracy: 87.10%\n",
      "Step 37500, Loss: 0.1643, Accuracy: 86.33%\n",
      "Step 40000, Loss: 0.7269, Accuracy: 48.50%\n",
      "Step 42500, Loss: 0.1380, Accuracy: 84.52%\n",
      "Step 45000, Loss: 0.0950, Accuracy: 87.15%\n",
      "Step 47500, Loss: 0.1788, Accuracy: 86.80%\n",
      "Step 50000, Loss: 0.1278, Accuracy: 86.80%\n",
      "Final accuracy: 86.80%\n",
      "--- Training model: d128_2L_noLN_Bias_uWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37dd3eb035a64f85ac61fa2782c47afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.7032, Accuracy: 47.73%\n",
      "Step 5000, Loss: 0.7018, Accuracy: 47.40%\n",
      "Step 7500, Loss: 0.6975, Accuracy: 46.45%\n",
      "Step 10000, Loss: 0.6997, Accuracy: 46.45%\n",
      "Step 12500, Loss: 0.6827, Accuracy: 45.73%\n",
      "Step 15000, Loss: 0.7120, Accuracy: 45.90%\n",
      "Step 17500, Loss: 0.6843, Accuracy: 46.58%\n",
      "Step 20000, Loss: 0.6848, Accuracy: 46.08%\n",
      "Step 22500, Loss: 0.6915, Accuracy: 45.52%\n",
      "Step 25000, Loss: 0.6997, Accuracy: 46.52%\n",
      "Step 27500, Loss: 0.6941, Accuracy: 46.17%\n",
      "Step 30000, Loss: 0.7091, Accuracy: 45.70%\n",
      "Step 32500, Loss: 0.6701, Accuracy: 45.57%\n",
      "Step 35000, Loss: 0.1887, Accuracy: 86.85%\n",
      "Step 37500, Loss: 0.0891, Accuracy: 89.65%\n",
      "Step 40000, Loss: 0.7625, Accuracy: 47.90%\n",
      "Step 42500, Loss: 0.1736, Accuracy: 86.25%\n",
      "Step 45000, Loss: 0.0916, Accuracy: 88.10%\n",
      "Step 47500, Loss: 0.1224, Accuracy: 88.33%\n",
      "Step 50000, Loss: 0.1188, Accuracy: 89.45%\n",
      "Final accuracy: 89.45%\n",
      "--- Training model: d128_2L_noLN_Bias_fWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a339984f7e1941848584fa84590d352e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.6890, Accuracy: 47.33%\n",
      "Step 5000, Loss: 0.6998, Accuracy: 48.30%\n",
      "Step 7500, Loss: 0.7076, Accuracy: 47.52%\n",
      "Step 10000, Loss: 0.6933, Accuracy: 47.33%\n",
      "Step 12500, Loss: 0.6735, Accuracy: 47.08%\n",
      "Step 15000, Loss: 0.7062, Accuracy: 47.40%\n",
      "Step 17500, Loss: 0.7009, Accuracy: 47.15%\n",
      "Step 20000, Loss: 0.6932, Accuracy: 47.83%\n",
      "Step 22500, Loss: 0.7002, Accuracy: 46.95%\n",
      "Step 25000, Loss: 0.6899, Accuracy: 47.10%\n",
      "Step 27500, Loss: 0.7115, Accuracy: 47.48%\n",
      "Step 30000, Loss: 0.6883, Accuracy: 47.60%\n",
      "Step 32500, Loss: 0.6938, Accuracy: 47.42%\n",
      "Step 35000, Loss: 0.6963, Accuracy: 46.73%\n",
      "Step 37500, Loss: 0.7013, Accuracy: 46.38%\n",
      "Step 40000, Loss: 0.6984, Accuracy: 47.40%\n",
      "Step 42500, Loss: 0.6829, Accuracy: 47.12%\n",
      "Step 45000, Loss: 0.6942, Accuracy: 46.77%\n",
      "Step 47500, Loss: 0.7040, Accuracy: 47.08%\n",
      "Step 50000, Loss: 0.6864, Accuracy: 46.45%\n",
      "Final accuracy: 46.45%\n",
      "--- Training model: d128_2L_noLN_Bias_fWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a582ff19434c4a11a49d052a78bd4473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.6870, Accuracy: 44.20%\n",
      "Step 5000, Loss: 0.6983, Accuracy: 45.60%\n",
      "Step 7500, Loss: 0.6864, Accuracy: 45.32%\n",
      "Step 10000, Loss: 0.7014, Accuracy: 44.62%\n",
      "Step 12500, Loss: 0.6864, Accuracy: 45.32%\n",
      "Step 15000, Loss: 0.6788, Accuracy: 45.00%\n",
      "Step 17500, Loss: 0.6799, Accuracy: 43.80%\n",
      "Step 20000, Loss: 0.6637, Accuracy: 44.98%\n",
      "Step 22500, Loss: 0.2642, Accuracy: 84.67%\n",
      "Step 25000, Loss: 0.1716, Accuracy: 88.28%\n",
      "Step 27500, Loss: 0.1228, Accuracy: 89.45%\n",
      "Step 30000, Loss: 0.1384, Accuracy: 90.42%\n",
      "Step 32500, Loss: 0.0877, Accuracy: 91.17%\n",
      "Step 35000, Loss: 0.1052, Accuracy: 90.90%\n",
      "Step 37500, Loss: 0.1284, Accuracy: 90.92%\n",
      "Step 40000, Loss: 0.1152, Accuracy: 90.38%\n",
      "Step 42500, Loss: 0.0888, Accuracy: 91.00%\n",
      "Step 45000, Loss: 0.0796, Accuracy: 90.75%\n",
      "Step 47500, Loss: 0.0787, Accuracy: 91.95%\n",
      "Step 50000, Loss: 0.0739, Accuracy: 91.83%\n",
      "Final accuracy: 91.83%\n",
      "--- Training model: d128_2L_LN_noBias_uWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff06fa3c0e9401e8d31cb3559e6e9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.7132, Accuracy: 49.10%\n",
      "Step 5000, Loss: 0.7055, Accuracy: 48.93%\n",
      "Step 7500, Loss: 0.7110, Accuracy: 48.30%\n",
      "Step 10000, Loss: 0.7004, Accuracy: 49.05%\n",
      "Step 12500, Loss: 0.7186, Accuracy: 48.65%\n",
      "Step 15000, Loss: 0.7026, Accuracy: 48.88%\n",
      "Step 17500, Loss: 0.7061, Accuracy: 48.33%\n",
      "Step 20000, Loss: 0.6962, Accuracy: 48.43%\n",
      "Step 22500, Loss: 0.7084, Accuracy: 48.43%\n",
      "Step 25000, Loss: 0.7025, Accuracy: 48.33%\n",
      "Step 27500, Loss: 0.7091, Accuracy: 48.45%\n",
      "Step 30000, Loss: 0.7145, Accuracy: 47.88%\n",
      "Step 32500, Loss: 0.7074, Accuracy: 47.58%\n",
      "Step 35000, Loss: 0.6918, Accuracy: 48.12%\n",
      "Step 37500, Loss: 0.7014, Accuracy: 48.18%\n",
      "Step 40000, Loss: 0.7020, Accuracy: 47.50%\n",
      "Step 42500, Loss: 0.6960, Accuracy: 47.55%\n",
      "Step 45000, Loss: 0.6892, Accuracy: 47.20%\n",
      "Step 47500, Loss: 0.7000, Accuracy: 47.85%\n",
      "Step 50000, Loss: 0.6985, Accuracy: 47.42%\n",
      "Final accuracy: 47.42%\n",
      "--- Training model: d128_2L_LN_noBias_uWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c32edacab0e4f88bcaa1a9cbbb1fa90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.7124, Accuracy: 48.23%\n",
      "Step 5000, Loss: 0.7081, Accuracy: 49.02%\n",
      "Step 7500, Loss: 0.6985, Accuracy: 47.83%\n",
      "Step 10000, Loss: 0.6995, Accuracy: 47.88%\n",
      "Step 12500, Loss: 0.6801, Accuracy: 48.95%\n",
      "Step 15000, Loss: 0.7006, Accuracy: 47.85%\n",
      "Step 17500, Loss: 0.6809, Accuracy: 48.15%\n",
      "Step 20000, Loss: 0.6960, Accuracy: 47.93%\n",
      "Step 22500, Loss: 0.6966, Accuracy: 47.98%\n",
      "Step 25000, Loss: 0.7002, Accuracy: 47.60%\n",
      "Step 27500, Loss: 0.7001, Accuracy: 47.55%\n",
      "Step 30000, Loss: 0.7000, Accuracy: 47.83%\n",
      "Step 32500, Loss: 0.6937, Accuracy: 47.20%\n",
      "Step 35000, Loss: 0.6912, Accuracy: 47.42%\n",
      "Step 37500, Loss: 0.6951, Accuracy: 46.90%\n",
      "Step 40000, Loss: 0.6803, Accuracy: 47.25%\n",
      "Step 42500, Loss: 0.6934, Accuracy: 46.70%\n",
      "Step 45000, Loss: 0.6908, Accuracy: 45.73%\n",
      "Step 47500, Loss: 0.6836, Accuracy: 46.10%\n",
      "Step 50000, Loss: 0.6979, Accuracy: 46.08%\n",
      "Final accuracy: 46.08%\n",
      "--- Training model: d128_2L_LN_noBias_fWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10215368d88418eb0279c543c5cb356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.7041, Accuracy: 49.08%\n",
      "Step 5000, Loss: 0.6938, Accuracy: 48.40%\n",
      "Step 7500, Loss: 0.7077, Accuracy: 47.80%\n",
      "Step 10000, Loss: 0.7173, Accuracy: 47.75%\n",
      "Step 12500, Loss: 0.7030, Accuracy: 47.88%\n",
      "Step 15000, Loss: 0.7042, Accuracy: 48.38%\n",
      "Step 17500, Loss: 0.6946, Accuracy: 47.95%\n",
      "Step 20000, Loss: 0.6936, Accuracy: 47.25%\n",
      "Step 22500, Loss: 0.6954, Accuracy: 48.62%\n",
      "Step 25000, Loss: 0.6909, Accuracy: 47.83%\n",
      "Step 27500, Loss: 0.7022, Accuracy: 47.50%\n",
      "Step 30000, Loss: 0.6982, Accuracy: 46.45%\n",
      "Step 32500, Loss: 0.6958, Accuracy: 47.05%\n",
      "Step 35000, Loss: 0.6928, Accuracy: 47.48%\n",
      "Step 37500, Loss: 0.6909, Accuracy: 47.30%\n",
      "Step 40000, Loss: 0.6767, Accuracy: 46.42%\n",
      "Step 42500, Loss: 0.6890, Accuracy: 46.30%\n",
      "Step 45000, Loss: 0.6945, Accuracy: 46.55%\n",
      "Step 47500, Loss: 0.7045, Accuracy: 45.88%\n",
      "Step 50000, Loss: 0.6837, Accuracy: 46.33%\n",
      "Final accuracy: 46.33%\n",
      "--- Training model: d128_2L_LN_noBias_fWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93287db8843450b82c15f60fb6ffff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.6979, Accuracy: 47.77%\n",
      "Step 5000, Loss: 0.6892, Accuracy: 47.15%\n",
      "Step 7500, Loss: 0.6913, Accuracy: 47.70%\n",
      "Step 10000, Loss: 0.6872, Accuracy: 47.27%\n",
      "Step 12500, Loss: 0.6999, Accuracy: 46.23%\n",
      "Step 15000, Loss: 0.6946, Accuracy: 46.35%\n",
      "Step 17500, Loss: 0.6988, Accuracy: 46.12%\n",
      "Step 20000, Loss: 0.6780, Accuracy: 46.38%\n",
      "Step 22500, Loss: 0.6934, Accuracy: 45.30%\n",
      "Step 25000, Loss: 0.6947, Accuracy: 45.52%\n",
      "Step 27500, Loss: 0.6942, Accuracy: 45.73%\n",
      "Step 30000, Loss: 0.6872, Accuracy: 44.62%\n",
      "Step 32500, Loss: 0.6823, Accuracy: 45.75%\n",
      "Step 35000, Loss: 0.6925, Accuracy: 46.65%\n",
      "Step 37500, Loss: 0.6880, Accuracy: 46.38%\n",
      "Step 40000, Loss: 0.6930, Accuracy: 44.25%\n",
      "Step 42500, Loss: 0.6984, Accuracy: 45.23%\n",
      "Step 45000, Loss: 0.6936, Accuracy: 45.25%\n",
      "Step 47500, Loss: 0.6969, Accuracy: 43.97%\n",
      "Step 50000, Loss: 0.6804, Accuracy: 44.85%\n",
      "Final accuracy: 44.85%\n",
      "--- Training model: d128_2L_LN_Bias_uWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415028e3e7f34dd48c3d1804c1b8a634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.7271, Accuracy: 48.93%\n",
      "Step 5000, Loss: 0.7258, Accuracy: 48.58%\n",
      "Step 7500, Loss: 0.7052, Accuracy: 49.00%\n",
      "Step 10000, Loss: 0.7032, Accuracy: 48.10%\n",
      "Step 12500, Loss: 0.7116, Accuracy: 49.02%\n",
      "Step 15000, Loss: 0.6980, Accuracy: 48.85%\n",
      "Step 17500, Loss: 0.6961, Accuracy: 48.35%\n",
      "Step 20000, Loss: 0.7033, Accuracy: 47.85%\n",
      "Step 22500, Loss: 0.7064, Accuracy: 48.45%\n",
      "Step 25000, Loss: 0.7103, Accuracy: 47.88%\n",
      "Step 27500, Loss: 0.7014, Accuracy: 48.20%\n",
      "Step 30000, Loss: 0.6998, Accuracy: 48.25%\n",
      "Step 32500, Loss: 0.6927, Accuracy: 47.58%\n",
      "Step 35000, Loss: 0.6952, Accuracy: 47.45%\n",
      "Step 37500, Loss: 0.7088, Accuracy: 48.43%\n",
      "Step 40000, Loss: 0.7021, Accuracy: 47.15%\n",
      "Step 42500, Loss: 0.6880, Accuracy: 47.62%\n",
      "Step 45000, Loss: 0.6996, Accuracy: 47.42%\n",
      "Step 47500, Loss: 0.6801, Accuracy: 47.27%\n",
      "Step 50000, Loss: 0.6926, Accuracy: 47.33%\n",
      "Final accuracy: 47.33%\n",
      "--- Training model: d128_2L_LN_Bias_uWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97f9ac1c73144f2af32afc8bc7b6d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.7131, Accuracy: 48.20%\n",
      "Step 5000, Loss: 0.7094, Accuracy: 48.60%\n",
      "Step 7500, Loss: 0.6894, Accuracy: 48.02%\n",
      "Step 10000, Loss: 0.6902, Accuracy: 47.85%\n",
      "Step 12500, Loss: 0.7085, Accuracy: 47.93%\n",
      "Step 15000, Loss: 0.6969, Accuracy: 48.20%\n",
      "Step 17500, Loss: 0.6922, Accuracy: 47.90%\n",
      "Step 20000, Loss: 0.7090, Accuracy: 47.23%\n",
      "Step 22500, Loss: 0.6972, Accuracy: 47.12%\n",
      "Step 25000, Loss: 0.6794, Accuracy: 47.25%\n",
      "Step 27500, Loss: 0.6982, Accuracy: 46.77%\n",
      "Step 30000, Loss: 0.6873, Accuracy: 47.25%\n",
      "Step 32500, Loss: 0.6996, Accuracy: 46.58%\n",
      "Step 35000, Loss: 0.6890, Accuracy: 46.88%\n",
      "Step 37500, Loss: 0.6814, Accuracy: 46.88%\n",
      "Step 40000, Loss: 0.6896, Accuracy: 47.23%\n",
      "Step 42500, Loss: 0.6688, Accuracy: 46.75%\n",
      "Step 45000, Loss: 0.6927, Accuracy: 46.55%\n",
      "Step 47500, Loss: 0.6808, Accuracy: 46.52%\n",
      "Step 50000, Loss: 0.6876, Accuracy: 46.48%\n",
      "Final accuracy: 46.48%\n",
      "--- Training model: d128_2L_LN_Bias_fWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3112419ed64dd89f869063f8181aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.7166, Accuracy: 49.10%\n",
      "Step 5000, Loss: 0.7174, Accuracy: 49.18%\n",
      "Step 7500, Loss: 0.6985, Accuracy: 47.25%\n",
      "Step 10000, Loss: 0.7136, Accuracy: 48.25%\n",
      "Step 12500, Loss: 0.6925, Accuracy: 47.98%\n",
      "Step 15000, Loss: 0.7050, Accuracy: 48.45%\n",
      "Step 17500, Loss: 0.7079, Accuracy: 47.40%\n",
      "Step 20000, Loss: 0.7000, Accuracy: 48.10%\n",
      "Step 22500, Loss: 0.6979, Accuracy: 47.67%\n",
      "Step 25000, Loss: 0.7036, Accuracy: 47.25%\n",
      "Step 27500, Loss: 0.7014, Accuracy: 47.88%\n",
      "Step 30000, Loss: 0.6789, Accuracy: 47.45%\n",
      "Step 32500, Loss: 0.6913, Accuracy: 47.83%\n",
      "Step 35000, Loss: 0.6880, Accuracy: 47.75%\n",
      "Step 37500, Loss: 0.6872, Accuracy: 47.45%\n",
      "Step 40000, Loss: 0.6790, Accuracy: 46.60%\n",
      "Step 42500, Loss: 0.7044, Accuracy: 47.48%\n",
      "Step 45000, Loss: 0.7009, Accuracy: 46.80%\n",
      "Step 47500, Loss: 0.6951, Accuracy: 46.17%\n",
      "Step 50000, Loss: 0.6882, Accuracy: 47.55%\n",
      "Final accuracy: 47.55%\n",
      "--- Training model: d128_2L_LN_Bias_fWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a37abead2d49f499df94e29fe8676e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.7094, Accuracy: 50.02%\n",
      "Step 5000, Loss: 0.6913, Accuracy: 46.40%\n",
      "Step 7500, Loss: 0.6942, Accuracy: 47.02%\n",
      "Step 10000, Loss: 0.6891, Accuracy: 46.50%\n",
      "Step 12500, Loss: 0.6982, Accuracy: 46.67%\n",
      "Step 15000, Loss: 0.7003, Accuracy: 46.40%\n",
      "Step 17500, Loss: 0.6972, Accuracy: 46.90%\n",
      "Step 20000, Loss: 0.6811, Accuracy: 46.50%\n",
      "Step 22500, Loss: 0.6914, Accuracy: 46.27%\n",
      "Step 25000, Loss: 0.6666, Accuracy: 46.10%\n",
      "Step 27500, Loss: 0.6747, Accuracy: 46.83%\n",
      "Step 30000, Loss: 0.6730, Accuracy: 46.15%\n",
      "Step 32500, Loss: 0.6968, Accuracy: 46.48%\n",
      "Step 35000, Loss: 0.6911, Accuracy: 46.08%\n",
      "Step 37500, Loss: 0.6845, Accuracy: 46.27%\n",
      "Step 40000, Loss: 0.6966, Accuracy: 44.73%\n",
      "Step 42500, Loss: 0.6931, Accuracy: 46.30%\n",
      "Step 45000, Loss: 0.6731, Accuracy: 46.95%\n",
      "Step 47500, Loss: 0.6909, Accuracy: 45.88%\n",
      "Step 50000, Loss: 0.6917, Accuracy: 46.02%\n",
      "Final accuracy: 46.02%\n",
      "--- Training model: d128_3L_noLN_noBias_uWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825865fc5e5e44c881c158747da51944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 100 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_noLN_noBias_uWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7a38be7f2047c3aebe03f6052dea6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 100 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_noLN_noBias_fWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61980850ee344108b0878fff93717ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 100 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_noLN_noBias_fWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4cc183974e46f48bc6cf786b28ce64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.6923, Accuracy: 43.45%\n",
      "Early stopping at step 3300 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_noLN_Bias_uWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22808006e33f476ab879e1f97de0e6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 100 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_noLN_Bias_uWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74bdaf882a042c6bd413d5cb20be715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 100 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_noLN_Bias_fWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b1733a426140f390cb0b6072a3525c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 100 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_noLN_Bias_fWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc9162f587b45a498f197ffc560e75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.6869, Accuracy: 46.80%\n",
      "Early stopping at step 2800 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_LN_noBias_uWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4236b6418b5444a391d9dd82ddc48faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 100 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_LN_noBias_uWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac59a8f8d0243b9b4e83d35bf477101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 100 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_LN_noBias_fWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5895d4928df14911b697db5e91adeb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 100 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_LN_noBias_fWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda4d15c2b564f33abea32d721a7b8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 100 with accuracy 99.92% >= 99.90%\n",
      "Final accuracy: 99.92%\n",
      "--- Training model: d128_3L_LN_Bias_uWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175a9c2ec0024f4abba3f081aa0192ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 100 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_LN_Bias_uWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a327e9af7a6f4593b6dc6eceee402378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 100 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_LN_Bias_fWV_uWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e039e41abab4486b2bce6e475fbb1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 100 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "--- Training model: d128_3L_LN_Bias_fWV_fWO ---\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf11c0c3b2b416d8169e40b3032959c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 200 with accuracy 100.00% >= 99.90%\n",
      "Final accuracy: 100.00%\n",
      "| name                        |   n_layers |   n_heads |   d_model | ln    | use_bias   | freeze_wv   | freeze_wo   |   weight_decay |   val_acc |\n",
      "|:----------------------------|-----------:|----------:|----------:|:------|:-----------|:------------|:------------|---------------:|----------:|\n",
      "| d128_2L_noLN_noBias_uWV_uWO |          2 |         1 |       128 | False | False      | False       | False       |           0.01 |    0.4625 |\n",
      "| d128_2L_noLN_noBias_uWV_fWO |          2 |         1 |       128 | False | False      | False       | True        |           0.01 |    0.4895 |\n",
      "| d128_2L_noLN_noBias_fWV_uWO |          2 |         1 |       128 | False | False      | True        | False       |           0.01 |    0.463  |\n",
      "| d128_2L_noLN_noBias_fWV_fWO |          2 |         1 |       128 | False | False      | True        | True        |           0.01 |    0.9173 |\n",
      "| d128_2L_noLN_Bias_uWV_uWO   |          2 |         1 |       128 | False | True       | False       | False       |           0.01 |    0.868  |\n",
      "| d128_2L_noLN_Bias_uWV_fWO   |          2 |         1 |       128 | False | True       | False       | True        |           0.01 |    0.8945 |\n",
      "| d128_2L_noLN_Bias_fWV_uWO   |          2 |         1 |       128 | False | True       | True        | False       |           0.01 |    0.4645 |\n",
      "| d128_2L_noLN_Bias_fWV_fWO   |          2 |         1 |       128 | False | True       | True        | True        |           0.01 |    0.9183 |\n",
      "| d128_2L_LN_noBias_uWV_uWO   |          2 |         1 |       128 | True  | False      | False       | False       |           0.01 |    0.4743 |\n",
      "| d128_2L_LN_noBias_uWV_fWO   |          2 |         1 |       128 | True  | False      | False       | True        |           0.01 |    0.4607 |\n",
      "| d128_2L_LN_noBias_fWV_uWO   |          2 |         1 |       128 | True  | False      | True        | False       |           0.01 |    0.4632 |\n",
      "| d128_2L_LN_noBias_fWV_fWO   |          2 |         1 |       128 | True  | False      | True        | True        |           0.01 |    0.4485 |\n",
      "| d128_2L_LN_Bias_uWV_uWO     |          2 |         1 |       128 | True  | True       | False       | False       |           0.01 |    0.4733 |\n",
      "| d128_2L_LN_Bias_uWV_fWO     |          2 |         1 |       128 | True  | True       | False       | True        |           0.01 |    0.4647 |\n",
      "| d128_2L_LN_Bias_fWV_uWO     |          2 |         1 |       128 | True  | True       | True        | False       |           0.01 |    0.4755 |\n",
      "| d128_2L_LN_Bias_fWV_fWO     |          2 |         1 |       128 | True  | True       | True        | True        |           0.01 |    0.4602 |\n",
      "| d128_3L_noLN_noBias_uWV_uWO |          3 |         1 |       128 | False | False      | False       | False       |           0.01 |    1      |\n",
      "| d128_3L_noLN_noBias_uWV_fWO |          3 |         1 |       128 | False | False      | False       | True        |           0.01 |    1      |\n",
      "| d128_3L_noLN_noBias_fWV_uWO |          3 |         1 |       128 | False | False      | True        | False       |           0.01 |    1      |\n",
      "| d128_3L_noLN_noBias_fWV_fWO |          3 |         1 |       128 | False | False      | True        | True        |           0.01 |    1      |\n",
      "| d128_3L_noLN_Bias_uWV_uWO   |          3 |         1 |       128 | False | True       | False       | False       |           0.01 |    1      |\n",
      "| d128_3L_noLN_Bias_uWV_fWO   |          3 |         1 |       128 | False | True       | False       | True        |           0.01 |    1      |\n",
      "| d128_3L_noLN_Bias_fWV_uWO   |          3 |         1 |       128 | False | True       | True        | False       |           0.01 |    1      |\n",
      "| d128_3L_noLN_Bias_fWV_fWO   |          3 |         1 |       128 | False | True       | True        | True        |           0.01 |    1      |\n",
      "| d128_3L_LN_noBias_uWV_uWO   |          3 |         1 |       128 | True  | False      | False       | False       |           0.01 |    1      |\n",
      "| d128_3L_LN_noBias_uWV_fWO   |          3 |         1 |       128 | True  | False      | False       | True        |           0.01 |    1      |\n",
      "| d128_3L_LN_noBias_fWV_uWO   |          3 |         1 |       128 | True  | False      | True        | False       |           0.01 |    1      |\n",
      "| d128_3L_LN_noBias_fWV_fWO   |          3 |         1 |       128 | True  | False      | True        | True        |           0.01 |    0.9992 |\n",
      "| d128_3L_LN_Bias_uWV_uWO     |          3 |         1 |       128 | True  | True       | False       | False       |           0.01 |    1      |\n",
      "| d128_3L_LN_Bias_uWV_fWO     |          3 |         1 |       128 | True  | True       | False       | True        |           0.01 |    1      |\n",
      "| d128_3L_LN_Bias_fWV_uWO     |          3 |         1 |       128 | True  | True       | True        | False       |           0.01 |    1      |\n",
      "| d128_3L_LN_Bias_fWV_fWO     |          3 |         1 |       128 | True  | True       | True        | True        |           0.01 |    1      |\n"
     ]
    }
   ],
   "source": [
    "# ---------- experiment grid ----------\n",
    "from itertools import product\n",
    "\n",
    "def make_name(d_model, n_layers, ln, use_bias, freeze_wv, freeze_wo):\n",
    "    parts = [\n",
    "        f\"d{d_model}\",\n",
    "        f\"{n_layers}L\",\n",
    "        (\"LN\" if ln else \"noLN\"),\n",
    "        (\"Bias\" if use_bias else \"noBias\"),\n",
    "        (\"fWV\" if freeze_wv else \"uWV\"), # freeze / unfreeze\n",
    "        (\"fWO\" if freeze_wo else \"uWO\"),\n",
    "    ]\n",
    "    return \"_\".join(parts)\n",
    "\n",
    "specs = [\n",
    "    # {'name': 'd128', 'd_model': 128},\n",
    "    # {'name': 'd64', 'd_model': 64},\n",
    "    \n",
    "    # {'name': 'd32', 'd_model': 32},\n",
    "    # {'name': 'd32_ln_bias', 'd_model': 32, 'ln': True, 'use_bias': True},\n",
    "    # {'name': 'd32_noLN', 'd_model': 32, 'ln': False, 'use_bias': True},\n",
    "    # {'name': 'd32_noBias', 'd_model': 32, 'ln': True, 'use_bias': False},\n",
    "    # {'name': 'd32_noLNnoBias', 'd_model': 32, 'ln': False, 'use_bias': False},\n",
    "    # {'name': 'd32_fwo', 'd_model': 32, 'freeze_wo': True},\n",
    "    # {'name': 'd32_unfwo', 'd_model': 32, 'freeze_wo': False},\n",
    "\n",
    "    # {'name': 'd16', 'd_model': 16},\n",
    "    # {'name': 'd16_ln_bias', 'd_model': 16, 'ln': True, 'use_bias': True},\n",
    "    # {'name': 'd16_noLN', 'd_model': 16, 'ln': False, 'use_bias': True},\n",
    "    # {'name': 'd16_noBias', 'd_model': 16, 'ln': True, 'use_bias': False},\n",
    "    # {'name': 'd16_noLNnoBias', 'd_model': 16, 'ln': False, 'use_bias': False},\n",
    "    # {'name': 'd16_fwo', 'd_model': 16, 'freeze_wo': True},\n",
    "    # {'name': 'd16_unfwo', 'd_model': 16, 'freeze_wo': False},\n",
    "\n",
    "    # {'name': 'd8', 'd_model': 8},\n",
    "    # {'name': 'd8_ln_bias', 'd_model': 8, 'ln': True, 'use_bias': True},\n",
    "    # {'name': 'd8_noLN', 'd_model': 8, 'ln': False, 'use_bias': True},\n",
    "    # {'name': 'd8_noBias', 'd_model': 8, 'ln': True, 'use_bias': False},\n",
    "    # {'name': 'd8_noLNnoBias', 'd_model': 8, 'ln': False, 'use_bias': False},\n",
    "    # {'name': 'd8_fwo', 'd_model': 8, 'freeze_wo': True},\n",
    "    # {'name': 'd8_unfwo', 'd_model': 8, 'freeze_wo': False},\n",
    "\n",
    "    # {'name': 'd4_ln_bias', 'd_model': 4, 'ln': True, 'use_bias': True},\n",
    "]\n",
    "\n",
    "# specs = []\n",
    "# d_model = 128\n",
    "# for n_layers, ln, use_bias, freeze_wv, freeze_wo in product(\n",
    "#     [2, 3],            # layers\n",
    "#     [False, True],     # ln\n",
    "#     [False, True],     # use_bias\n",
    "#     [False, True],     # freeze_wv\n",
    "#     [False, True],     # freeze_wo\n",
    "# ):\n",
    "#     specs.append({\n",
    "#         \"name\": make_name(d_model, n_layers, ln, use_bias, freeze_wv, freeze_wo),\n",
    "#         \"d_model\": d_model,\n",
    "#         \"n_layers\": n_layers,\n",
    "#         \"ln\": ln,\n",
    "#         \"use_bias\": use_bias,\n",
    "#         \"freeze_wv\": freeze_wv,\n",
    "#         \"freeze_wo\": freeze_wo,\n",
    "#     })\n",
    "\n",
    "# -----------------------\n",
    "rows = []\n",
    "for spec in specs:\n",
    "    # Create a full spec by starting with defaults and updating with the current spec\n",
    "    full_spec = {\n",
    "        'n_layers': N_LAYER,\n",
    "        'n_heads': N_HEAD,\n",
    "        'd_model': D_MODEL,\n",
    "        'ln': USE_LN,\n",
    "        'use_bias': USE_BIAS,\n",
    "        'freeze_wv': FREEZE_WV,\n",
    "        'freeze_wo': FREEZE_WO,\n",
    "        'weight_decay': WEIGHT_DECAY,\n",
    "    }\n",
    "    full_spec.update(spec) # Overwrite defaults with provided spec values\n",
    "\n",
    "    print(f\"--- Training model: {full_spec['name']} ---\")\n",
    "    model = make_model(\n",
    "        n_layers=full_spec['n_layers'],\n",
    "        n_heads=full_spec['n_heads'],\n",
    "        d_model=full_spec['d_model'], \n",
    "        ln=full_spec['ln'],\n",
    "        use_bias=full_spec['use_bias'],\n",
    "        freeze_wv=full_spec['freeze_wv'],\n",
    "        freeze_wo=full_spec['freeze_wo'],\n",
    "    )\n",
    "\n",
    "    train(model, max_steps=50_000, weight_decay=full_spec['weight_decay'], verbose=True)\n",
    "    \n",
    "    # Add all spec parameters to the results\n",
    "    result = full_spec.copy()\n",
    "    result['val_acc'] = round(accuracy(model), 4)\n",
    "    rows.append(result)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Move 'name' column to the front for better readability\n",
    "if 'name' in df.columns:\n",
    "    cols = ['name'] + [col for col in df.columns if col != 'name']\n",
    "    df = df[cols]\n",
    "\n",
    "print(df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d7ce1",
   "metadata": {},
   "source": [
    "| name                        |   n_layers |   n_heads |   d_model | ln    | use_bias   | freeze_wv   | freeze_wo   |   weight_decay |   val_acc |\n",
    "|:----------------------------|-----------:|----------:|----------:|:------|:-----------|:------------|:------------|---------------:|----------:|\n",
    "| d128_2L_noLN_noBias_uWV_uWO |          2 |         1 |       128 | False | False      | False       | False       |           0.01 |    0.4625 |\n",
    "| d128_2L_noLN_noBias_uWV_fWO |          2 |         1 |       128 | False | False      | False       | True        |           0.01 |    0.4895 |\n",
    "| d128_2L_noLN_noBias_fWV_uWO |          2 |         1 |       128 | False | False      | True        | False       |           0.01 |    0.463  |\n",
    "| d128_2L_noLN_noBias_fWV_fWO |          2 |         1 |       128 | False | False      | True        | True        |           0.01 |    0.9173 |\n",
    "| d128_2L_noLN_Bias_uWV_uWO   |          2 |         1 |       128 | False | True       | False       | False       |           0.01 |    0.868  |\n",
    "| d128_2L_noLN_Bias_uWV_fWO   |          2 |         1 |       128 | False | True       | False       | True        |           0.01 |    0.8945 |\n",
    "| d128_2L_noLN_Bias_fWV_uWO   |          2 |         1 |       128 | False | True       | True        | False       |           0.01 |    0.4645 |\n",
    "| d128_2L_noLN_Bias_fWV_fWO   |          2 |         1 |       128 | False | True       | True        | True        |           0.01 |    0.9183 |\n",
    "| d128_2L_LN_noBias_uWV_uWO   |          2 |         1 |       128 | True  | False      | False       | False       |           0.01 |    0.4743 |\n",
    "| d128_2L_LN_noBias_uWV_fWO   |          2 |         1 |       128 | True  | False      | False       | True        |           0.01 |    0.4607 |\n",
    "| d128_2L_LN_noBias_fWV_uWO   |          2 |         1 |       128 | True  | False      | True        | False       |           0.01 |    0.4632 |\n",
    "| d128_2L_LN_noBias_fWV_fWO   |          2 |         1 |       128 | True  | False      | True        | True        |           0.01 |    0.4485 |\n",
    "| d128_2L_LN_Bias_uWV_uWO     |          2 |         1 |       128 | True  | True       | False       | False       |           0.01 |    0.4733 |\n",
    "| d128_2L_LN_Bias_uWV_fWO     |          2 |         1 |       128 | True  | True       | False       | True        |           0.01 |    0.4647 |\n",
    "| d128_2L_LN_Bias_fWV_uWO     |          2 |         1 |       128 | True  | True       | True        | False       |           0.01 |    0.4755 |\n",
    "| d128_2L_LN_Bias_fWV_fWO     |          2 |         1 |       128 | True  | True       | True        | True        |           0.01 |    0.4602 |\n",
    "| d128_3L_noLN_noBias_uWV_uWO |          3 |         1 |       128 | False | False      | False       | False       |           0.01 |    1      |\n",
    "| d128_3L_noLN_noBias_uWV_fWO |          3 |         1 |       128 | False | False      | False       | True        |           0.01 |    1      |\n",
    "| d128_3L_noLN_noBias_fWV_uWO |          3 |         1 |       128 | False | False      | True        | False       |           0.01 |    1      |\n",
    "| d128_3L_noLN_noBias_fWV_fWO |          3 |         1 |       128 | False | False      | True        | True        |           0.01 |    1      |\n",
    "| d128_3L_noLN_Bias_uWV_uWO   |          3 |         1 |       128 | False | True       | False       | False       |           0.01 |    1      |\n",
    "| d128_3L_noLN_Bias_uWV_fWO   |          3 |         1 |       128 | False | True       | False       | True        |           0.01 |    1      |\n",
    "| d128_3L_noLN_Bias_fWV_uWO   |          3 |         1 |       128 | False | True       | True        | False       |           0.01 |    1      |\n",
    "| d128_3L_noLN_Bias_fWV_fWO   |          3 |         1 |       128 | False | True       | True        | True        |           0.01 |    1      |\n",
    "| d128_3L_LN_noBias_uWV_uWO   |          3 |         1 |       128 | True  | False      | False       | False       |           0.01 |    1      |\n",
    "| d128_3L_LN_noBias_uWV_fWO   |          3 |         1 |       128 | True  | False      | False       | True        |           0.01 |    1      |\n",
    "| d128_3L_LN_noBias_fWV_uWO   |          3 |         1 |       128 | True  | False      | True        | False       |           0.01 |    1      |\n",
    "| d128_3L_LN_noBias_fWV_fWO   |          3 |         1 |       128 | True  | False      | True        | True        |           0.01 |    0.9992 |\n",
    "| d128_3L_LN_Bias_uWV_uWO     |          3 |         1 |       128 | True  | True       | False       | False       |           0.01 |    1      |\n",
    "| d128_3L_LN_Bias_uWV_fWO     |          3 |         1 |       128 | True  | True       | False       | True        |           0.01 |    1      |\n",
    "| d128_3L_LN_Bias_fWV_uWO     |          3 |         1 |       128 | True  | True       | True        | False       |           0.01 |    1      |\n",
    "| d128_3L_LN_Bias_fWV_fWO     |          3 |         1 |       128 | True  | True       | True        | True        |           0.01 |    1      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e08dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from models/3layer_100dig_8d.pt\n",
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# LOAD existing or train and SAVE new model\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    model = load_model(MODEL_PATH, device=DEV)\n",
    "else:\n",
    "    print(\"Training model\")\n",
    "    model = make_model()\n",
    "    train(model, max_steps=MAX_TRAIN_STEPS, early_stop_acc=0.999, checkpoints=USE_CHECKPOINTING)\n",
    "    save_model(model, MODEL_PATH)\n",
    "\n",
    "# from torchinfo import summary\n",
    "# summary(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b456419a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Overview of Model Parameters ---\n",
      "Parameter Name                           | Shape                | Trainable \n",
      "--------------------------------------------------------------------------------\n",
      "embed.W_E                                | (101, 8)             | Yes       \n",
      "pos_embed.W_pos                          | (5, 8)               | Yes       \n",
      "blocks.0.attn.W_Q                        | (1, 8, 8)            | Yes       \n",
      "blocks.0.attn.W_K                        | (1, 8, 8)            | Yes       \n",
      "blocks.1.attn.W_Q                        | (1, 8, 8)            | Yes       \n",
      "blocks.1.attn.W_K                        | (1, 8, 8)            | Yes       \n",
      "blocks.2.attn.W_Q                        | (1, 8, 8)            | Yes       \n",
      "blocks.2.attn.W_K                        | (1, 8, 8)            | Yes       \n",
      "unembed.W_U                              | (8, 101)             | Yes       \n",
      "--------------------------------------------------------------------------------\n",
      "Total parameters: 2621\n",
      "Trainable parameters: 2040\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Model Parameters Overview ---\n",
    "\n",
    "print(\"--- Overview of Model Parameters ---\")\n",
    "total_params = 0\n",
    "trainable_params = 0\n",
    "\n",
    "# Use a formatted string for better alignment\n",
    "print(f\"{'Parameter Name':<40} | {'Shape':<20} | {'Trainable':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    shape_str = str(tuple(param.shape))\n",
    "    is_trainable = \"Yes\" if param.requires_grad else \"No\"\n",
    "    total_params += param.numel()\n",
    "\n",
    "    if not param.requires_grad:\n",
    "        continue\n",
    "    # Print only trainable parameters\n",
    "    print(f\"{name:<40} | {shape_str:<20} | {is_trainable:<10}\")\n",
    "    trainable_params += param.numel()\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a57f82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b984b78c",
   "metadata": {},
   "source": [
    "### Model attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75262f76",
   "metadata": {},
   "source": [
    "We confirm below that the model does not leak attention onto the first two tokens, which are the inputs to the task. The model should only attend to the first two tokens when predicting the third token, and not attend to them at all when predicting the fourth and fifth tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb560e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sequence: [ 80  52 100 100 100]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                    <div id=\"9909d777-1e8b-451b-a60c-d912185335de\" class=\"plotly-graph-div\" style=\"height:450px; width:1200px;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"9909d777-1e8b-451b-a60c-d912185335de\")) {                    Plotly.newPlot(                        \"9909d777-1e8b-451b-a60c-d912185335de\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"showscale\":false,\"x\":[\"d1\",\"d2\",\"SEP\",\"o1\",\"o2\"],\"y\":[\"d1\",\"d2\",\"SEP\",\"o1\",\"o2\"],\"z\":{\"dtype\":\"f4\",\"bdata\":\"AACAPwAAAAAAAAAAAAAAAAAAAAAAAIA\\u002fAAAAAAAAAAAAAAAAAAAAAAdUzT79VRk\\u002fAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIA\\u002fAAAAAAAAAAAAAAAAAAAAAAfZZj\\u002fNN8k9AAAAAA==\",\"shape\":\"5, 5\"},\"zmax\":1,\"zmin\":0,\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"showscale\":false,\"x\":[\"d1\",\"d2\",\"SEP\",\"o1\",\"o2\"],\"y\":[\"d1\",\"d2\",\"SEP\",\"o1\",\"o2\"],\"z\":{\"dtype\":\"f4\",\"bdata\":\"AACAPwAAAAAAAAAAAAAAAAAAAAAAAIA\\u002fAAAAAAAAAAAAAAAAAAAAADDnfz+aecY5AAAAAAAAAAAAAAAAAAAAAAAAAAAAAIA\\u002fAAAAAAAAAAAAAAAAAAAAAC2lcz8irUU9AAAAAA==\",\"shape\":\"5, 5\"},\"zmax\":1,\"zmin\":0,\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"showscale\":true,\"x\":[\"d1\",\"d2\",\"SEP\",\"o1\",\"o2\"],\"y\":[\"d1\",\"d2\",\"SEP\",\"o1\",\"o2\"],\"z\":{\"dtype\":\"f4\",\"bdata\":\"AACAPwAAAAAAAAAAAAAAAAAAAAAAAIA\\u002fAAAAAAAAAAAAAAAAAAAAANr\\u002ffz+lLxQ2AAAAAAAAAAAAAAAAAAAAAAAAAAAAAIA\\u002fAAAAAAAAAAAAAAAAAAAAAKNZVi0AAIA\\u002fAAAAAA==\",\"shape\":\"5, 5\"},\"zmax\":1,\"zmin\":0,\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scattermap\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermap\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.27999999999999997],\"title\":{\"text\":\"Key Position\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Query Position\"},\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.36,0.6399999999999999],\"title\":{\"text\":\"Key Position\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Query Position\"},\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.72,1.0],\"title\":{\"text\":\"Key Position\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Query Position\"},\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 0 Attention Pattern\",\"x\":0.13999999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 1 Attention Pattern\",\"x\":0.49999999999999994,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 2 Attention Pattern\",\"x\":0.86,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Attention Patterns for a Sample Sequence\"},\"width\":1200,\"height\":450},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('9909d777-1e8b-451b-a60c-d912185335de');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â no attention leakage onto xâ/xâ\n"
     ]
    }
   ],
   "source": [
    "# --- Using Plotly for visualization ---\n",
    "\n",
    "def check_attention(m, dataloader, eps=1e-3):\n",
    "    for inputs, _ in dataloader:\n",
    "        with torch.no_grad():\n",
    "            _, cache = m.run_with_cache(inputs.to(DEV))\n",
    "        for l in range(m.cfg.n_layers):\n",
    "            pat = cache[\"pattern\", l][:, 0]  # (batch, Q, K)\n",
    "            leak = pat[:, LIST_LEN+1:, :LIST_LEN].sum(dim=-1)  # mass on forbidden keys\n",
    "            if (leak > eps).any():\n",
    "                raise ValueError(f\"â Layer {l}: output tokens attend to xâ/xâ by >{eps:.0e}\")\n",
    "    print(\"â no attention leakage onto xâ/xâ\")\n",
    "\n",
    "\n",
    "sample = val_ds[0][0] # Example input sequence\n",
    "print(f\"Sample sequence: {sample.cpu().numpy()}\")  # Print the sample sequence for reference\n",
    "_, cache = model.run_with_cache(sample.unsqueeze(0).to(DEV))\n",
    "\n",
    "# --- Create Plotly visualization ---\n",
    "token_labels = [f'd{i+1}' for i in range(LIST_LEN)] + ['SEP'] + [f'o{i+1}' for i in range(LIST_LEN)]\n",
    "subplot_titles = [f\"Layer {l} Attention Pattern\" for l in range(model.cfg.n_layers)]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, \n",
    "    cols=model.cfg.n_layers, \n",
    "    subplot_titles=subplot_titles,\n",
    "    horizontal_spacing=0.08 # Add spacing between plots\n",
    ")\n",
    "\n",
    "for l in range(model.cfg.n_layers):\n",
    "    pat = cache[\"pattern\", l][0, 0].cpu().numpy()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=pat,\n",
    "            x=token_labels,\n",
    "            y=token_labels,\n",
    "            colorscale=\"Viridis\",\n",
    "            zmin=0,\n",
    "            zmax=1,\n",
    "            showscale=(l == model.cfg.n_layers - 1) # Show colorbar only for the last plot\n",
    "        ),\n",
    "        row=1, col=l+1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Attention Patterns for a Sample Sequence\",\n",
    "    width=1200,\n",
    "    height=450,\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Apply settings to all axes\n",
    "fig.update_xaxes(title_text=\"Key Position\")\n",
    "fig.update_yaxes(title_text=\"Query Position\", autorange='reversed')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "check_attention(model, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff11a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: all attention patterns identical? â\n",
      "Layer 1: all attention patterns identical? â\n",
      "Layer 2: all attention patterns identical? â\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                    <div id=\"f6b39f11-5c9f-44af-9b3d-b705988cbe2b\" class=\"plotly-graph-div\" style=\"height:450px; width:1200px;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"f6b39f11-5c9f-44af-9b3d-b705988cbe2b\")) {                    Plotly.newPlot(                        \"f6b39f11-5c9f-44af-9b3d-b705988cbe2b\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"showscale\":false,\"x\":[\"d1\",\"d2\",\"SEP\",\"o1\",\"o2\"],\"y\":[\"d1\",\"d2\",\"SEP\",\"o1\",\"o2\"],\"z\":{\"dtype\":\"f4\",\"bdata\":\"AACAPwAAAAAAAAAAAAAAAAAAAAAAAIA\\u002fAAAAAAAAAAAAAAAAAAAAAMbwmj6ehzI\\u002fAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIA\\u002fAAAAAAAAAAAAAAAAAAAAAAfZZj\\u002fNN8k9AAAAAA==\",\"shape\":\"5, 5\"},\"zmax\":1,\"zmin\":0,\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"showscale\":false,\"x\":[\"d1\",\"d2\",\"SEP\",\"o1\",\"o2\"],\"y\":[\"d1\",\"d2\",\"SEP\",\"o1\",\"o2\"],\"z\":{\"dtype\":\"f4\",\"bdata\":\"AACAPwAAAAAAAAAAAAAAAAAAAAAAAIA\\u002fAAAAAAAAAAAAAAAAAAAAAD8cfj+Z4PE7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAIA\\u002fAAAAAAAAAAAAAAAAAAAAAHDufD8oZEQ8AAAAAA==\",\"shape\":\"5, 5\"},\"zmax\":1,\"zmin\":0,\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"showscale\":true,\"x\":[\"d1\",\"d2\",\"SEP\",\"o1\",\"o2\"],\"y\":[\"d1\",\"d2\",\"SEP\",\"o1\",\"o2\"],\"z\":{\"dtype\":\"f4\",\"bdata\":\"AACAPwAAAAAAAAAAAAAAAAAAAAAAAIA\\u002fAAAAAAAAAAAAAAAAAAAAAL75wT4hAx8\\u002fAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIA\\u002fAAAAAAAAAAAAAAAAAAAAAORohDrNvX8\\u002fAAAAAA==\",\"shape\":\"5, 5\"},\"zmax\":1,\"zmin\":0,\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scattermap\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermap\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.27999999999999997],\"title\":{\"text\":\"Key Position\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Query Position\"},\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.36,0.6399999999999999],\"title\":{\"text\":\"Key Position\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Query Position\"},\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.72,1.0],\"title\":{\"text\":\"Key Position\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Query Position\"},\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 0 Average Attention\",\"x\":0.13999999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 1 Average Attention\",\"x\":0.49999999999999994,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 2 Average Attention\",\"x\":0.86,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Average Attention Patterns Across Validation Set\"},\"width\":1200,\"height\":450},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f6b39f11-5c9f-44af-9b3d-b705988cbe2b');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with avg-attn: 0.9915\n"
     ]
    }
   ],
   "source": [
    "# --- Mean Attention Patterns ---\n",
    "\n",
    "all_pats = [[] for _ in range(model.cfg.n_layers)]\n",
    "for inputs, _ in val_dl:\n",
    "    with torch.no_grad():\n",
    "        _, cache = model.run_with_cache(inputs.to(DEV))\n",
    "    for l in range(model.cfg.n_layers):\n",
    "        pat = cache[\"pattern\", l][:, 0]  # (batch, Q, K)\n",
    "        all_pats[l].append(pat)\n",
    "all_pats = [torch.cat(pats, dim=0) for pats in all_pats]\n",
    "\n",
    "for l, pats in enumerate(all_pats):\n",
    "    identical = torch.allclose(pats, pats[0].expand_as(pats))\n",
    "    print(f\"Layer {l}: all attention patterns identical? {'â' if identical else 'â'}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    avg_pats = [\n",
    "        torch.zeros(SEQ_LEN, SEQ_LEN, device=DEV) for _ in range(model.cfg.n_layers)\n",
    "    ]\n",
    "    n = 0\n",
    "    for inputs, _ in val_dl:\n",
    "        _, cache = model.run_with_cache(inputs.to(DEV))\n",
    "        for l in range(model.cfg.n_layers):\n",
    "            avg_pats[l] += cache[\"pattern\", l][:, 0].sum(0)\n",
    "        n += inputs.shape[0]\n",
    "    avg_pats = [p / n for p in avg_pats]\n",
    "\n",
    "# --- Visualize Average Attention Patterns ---\n",
    "token_labels = [f'd{i+1}' for i in range(LIST_LEN)] + ['SEP'] + [f'o{i+1}' for i in range(LIST_LEN)]\n",
    "subplot_titles = [f\"Layer {l} Average Attention\" for l in range(model.cfg.n_layers)]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, \n",
    "    cols=model.cfg.n_layers, \n",
    "    subplot_titles=subplot_titles,\n",
    "    horizontal_spacing=0.08\n",
    ")\n",
    "\n",
    "for l in range(model.cfg.n_layers):\n",
    "    avg_pat_np = avg_pats[l].cpu().numpy()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=avg_pat_np,\n",
    "            x=token_labels,\n",
    "            y=token_labels,\n",
    "            colorscale=\"Viridis\",\n",
    "            zmin=0,\n",
    "            zmax=1,\n",
    "            showscale=(l == model.cfg.n_layers - 1) # Show colorbar only for the last plot\n",
    "        ),\n",
    "        row=1, col=l+1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Average Attention Patterns Across Validation Set\",\n",
    "    width=1200,\n",
    "    height=450,\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Key Position\")\n",
    "fig.update_yaxes(title_text=\"Query Position\", autorange='reversed')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Create a deep copy of the model to avoid modifying the original\n",
    "model_with_avg_attn = copy.deepcopy(model)\n",
    "\n",
    "def mk_hook(avg):\n",
    "    logits = (avg + 1e-12).log()  # log-prob so softmaxâavg, Îµ avoids -â\n",
    "\n",
    "    def f(scores, hook):\n",
    "        return logits.unsqueeze(0).unsqueeze(0).expand_as(scores)\n",
    "\n",
    "    return f\n",
    "\n",
    "for l in range(model_with_avg_attn.cfg.n_layers):\n",
    "    model_with_avg_attn.blocks[l].attn.hook_attn_scores.add_hook(\n",
    "        mk_hook(avg_pats[l]), dir=\"fwd\"\n",
    "    )\n",
    "\n",
    "print(\"Accuracy with avg-attn:\", accuracy(model_with_avg_attn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
