{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52fcc20",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2de5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import copy\n",
    "from datetime import datetime # for unique model naming\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "import umap\n",
    "\n",
    "import einops\n",
    "import pandas as pd, itertools\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, utils\n",
    "\n",
    "from model_utils import strip_bias, set_WV_identity_and_freeze, set_WO_identity_and_freeze\n",
    "from data import get_dataset\n",
    "\n",
    "# Configure plotly to use static rendering if widgets fail\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "float_formatter = \"{:.5f}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15f0d1",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1437fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8252738730>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- parameters ----------\n",
    "LIST_LEN = 2 # [d1, d2]\n",
    "SEQ_LEN = LIST_LEN * 2 + 1 # [d1, d2, SEP, o1, o2]\n",
    "\n",
    "N_DIGITS = 100\n",
    "DIGITS = list(range(N_DIGITS)) # 100 digits from 0 to 99\n",
    "MASK = N_DIGITS # special masking token for o1 and o2\n",
    "SEP = N_DIGITS + 1 # special seperator token for the model to think about the input (+1 to avoid confusion with the last digit)\n",
    "VOCAB = len(DIGITS) + 2  # + the special tokens\n",
    "\n",
    "D_MODEL = 64\n",
    "N_HEAD = 1\n",
    "N_LAYER = 2\n",
    "USE_LN = False # use layer norm in model\n",
    "USE_BIAS = False # use bias in model\n",
    "FREEZE_WV = True # no value matrix in attn \n",
    "FREEZE_WO = True # no output matrix in attn (i.e. attn head can only copy inputs to outputs)\n",
    "\n",
    "LEARNING_RATE = 1e-3 # default 1e-3\n",
    "WEIGHT_DECAY = 0.01 # default 0.01\n",
    "MAX_TRAIN_STEPS = 50_000 # max training steps\n",
    "USE_CHECKPOINTING = False # whether to use checkpointing for training\n",
    "\n",
    "RUN_TS = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "MODEL_NAME = f'{N_LAYER}layer_{N_DIGITS}dig_{D_MODEL}d_{RUN_TS}'\n",
    "# MODEL_NAME = \n",
    "MODEL_PATH = \"models/\" + MODEL_NAME + \".pt\"\n",
    "\n",
    "# --- dataset --- (not necessary as we fix seed?)\n",
    "# DATASET_NAME = None # None ==> generate new one\n",
    "# listlen2_digits10_dupes\n",
    "# listlen2_digits10_nodupes\n",
    "# listlen2_digits100_dupes_traindupesonly\n",
    "# listlen2_digits100_dupes\n",
    "# listlen2_digits100_nodupes\n",
    "\n",
    "DEV = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "316797fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf],\n",
      "        [0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf],\n",
      "        [-inf, -inf, 0., -inf, -inf],\n",
      "        [-inf, -inf, 0., 0., -inf]])\n"
     ]
    }
   ],
   "source": [
    "# ---------- mask ----------\n",
    "# attention mask for [d1, d2, SEP, o1, o2] looks like this:\n",
    "# -    d1    d2    SEP    o1    o2   (keys)\n",
    "# d1  -inf  -inf   -inf  -inf  -inf\n",
    "# d2   0    -inf   -inf  -inf  -inf\n",
    "# SEP  0      0    -inf  -inf  -inf\n",
    "# o1  -inf  -inf    0    -inf   -inf\n",
    "# o2  -inf  -inf    0      0    -inf\n",
    "# (queries)\n",
    "\n",
    "mask_bias = torch.triu(torch.ones(SEQ_LEN, SEQ_LEN) * float(\"-inf\")) # upper triangular bias mask (lead_diag & above = -inf, rest = 0)\n",
    "mask_bias[0, 0] = 0. # don't want a full row of -inf! otherwise we get nan erros & training breaks\n",
    "mask_bias[LIST_LEN+1:, :LIST_LEN] = float(\"-inf\") # stop output tokens from attending to input tokens\n",
    "mask_bias = mask_bias.unsqueeze(0).unsqueeze(0) # (1,1,T,T) broadcastable across batch and heads\n",
    "\n",
    "# L0: keep outputs self-only and allow SEP->digits; avoid all -inf rows\n",
    "mask_bias_l0 = mask_bias.clone()\n",
    "mask_bias_l0[..., LIST_LEN+1:, :] = float(\"-inf\") # block all for outputs\n",
    "idx = torch.arange(LIST_LEN+1, SEQ_LEN)  # re-enable self for outputs\n",
    "mask_bias_l0[..., idx, idx] = 0.0\n",
    "\n",
    "print(mask_bias.cpu()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60abc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([ 60,  44, 101, 100, 100])\n",
      "Target: tensor([ 60,  44, 101,  60,  44])\n",
      "Train dataset size: 8000, Validation dataset size: 2000\n"
     ]
    }
   ],
   "source": [
    "# ---------- dataset ----------\n",
    "train_ds, val_ds = get_dataset(\n",
    "    list_len=LIST_LEN, \n",
    "    n_digits=N_DIGITS, \n",
    "    train_split=0.8,\n",
    "    mask_tok=MASK, # use MASK as mask token\n",
    "    sep_tok=SEP, # use SEP as separator token\n",
    "    )\n",
    "\n",
    "train_batch_size = min(128, len(train_ds))\n",
    "val_batch_size = min(256, len(val_ds))\n",
    "train_dl = DataLoader(train_ds, train_batch_size, shuffle=True, drop_last=True)\n",
    "val_dl = DataLoader(val_ds, val_batch_size, drop_last=False)\n",
    "\n",
    "print(\"Input:\", train_ds[0][0])\n",
    "print(\"Target:\", train_ds[0][1])\n",
    "print(f\"Train dataset size: {len(train_ds)}, Validation dataset size: {len(val_ds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7dbed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- config helper ----------\n",
    "def attach_custom_mask(model):\n",
    "    def _mask(scores, hook=None):\n",
    "        # scores: (batch, heads, Q, K)\n",
    "        return scores + mask_bias.to(scores.device)\n",
    "    \n",
    "    def _mask_l0(scores, hook=None):\n",
    "        # layer-0 special mask: o1/o2 only self; SEP can read d1/d2\n",
    "        return scores + mask_bias_l0.to(scores.device)\n",
    "    \n",
    "    # Completely suppress attention for oi in L0 (safe: zero pattern rows, not -inf scores)\n",
    "    def _zero_o_rows(pattern, hook=None):\n",
    "        # pattern: [B, H, Q, K]\n",
    "        start_o = LIST_LEN+1 # first o_i index\n",
    "        if start_o < SEQ_LEN:\n",
    "            pattern = pattern.clone()\n",
    "            pattern[..., start_o:SEQ_LEN, :] = 0.0\n",
    "        return pattern\n",
    "    \n",
    "    # register the same mask hook on every layer\n",
    "    for i, block in enumerate(model.blocks):\n",
    "        if i == 0:\n",
    "            block.attn.hook_attn_scores.add_perma_hook(_mask_l0, dir=\"fwd\")\n",
    "            block.attn.hook_pattern.add_perma_hook(_zero_o_rows, dir=\"fwd\")\n",
    "        else:\n",
    "            block.attn.hook_attn_scores.add_perma_hook(_mask, dir=\"fwd\")\n",
    "\n",
    "\n",
    "def make_model(n_layers=N_LAYER, n_heads=N_HEAD, d_model=D_MODEL, ln=USE_LN, use_bias=USE_BIAS, freeze_wv=FREEZE_WV, freeze_wo=FREEZE_WO):\n",
    "    cfg = HookedTransformerConfig(\n",
    "        n_layers = n_layers,\n",
    "        n_heads = n_heads,\n",
    "        d_model = d_model,\n",
    "        d_head = d_model//n_heads,\n",
    "        n_ctx=SEQ_LEN,\n",
    "        d_vocab=VOCAB,\n",
    "        attn_only=True, # no MLP!\n",
    "        normalization_type=(\"LN\" if ln else None),\n",
    "    )\n",
    "    model = HookedTransformer(cfg).to(DEV)\n",
    "    if freeze_wv:\n",
    "        set_WV_identity_and_freeze(model, d_model)\n",
    "    if freeze_wo:\n",
    "        set_WO_identity_and_freeze(model, d_model)\n",
    "    if not use_bias:\n",
    "        strip_bias(model)\n",
    "    \n",
    "    attach_custom_mask(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e326dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Model saving / loading helpers ------\n",
    "def save_model(model, path = MODEL_PATH):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def load_model(path = MODEL_PATH, device = DEV):\n",
    "    print(\"Loading model from\", path)\n",
    "    model = make_model()\n",
    "    model.load_state_dict(\n",
    "        torch.load(path, map_location=device)\n",
    "    )  # map weights to target device\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95071794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- utilities ----------\n",
    "def accuracy(m):\n",
    "    m.eval()\n",
    "    hits = tots = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_dl:\n",
    "            logits = m(inputs.to(DEV))[:, LIST_LEN+1:]  # (batch, 2, vocab)\n",
    "            preds = logits.argmax(-1)\n",
    "            hits += (preds == targets[:, LIST_LEN+1:].to(DEV)).sum().item()\n",
    "            tots += preds.numel()\n",
    "    return hits / tots\n",
    "\n",
    "\n",
    "def train(m, max_steps=10_000, early_stop_acc=0.999, checkpoints=False, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, verbose=True):\n",
    "    opt = torch.optim.AdamW(m.parameters(), lr, weight_decay=weight_decay)\n",
    "    ce = torch.nn.CrossEntropyLoss()\n",
    "    dl = itertools.cycle(train_dl)  # infinite iterator\n",
    "    for step in tqdm(range(max_steps), desc=\"Training\"):\n",
    "        inputs, targets = next(dl)\n",
    "        # get logits/loss for output tokens only\n",
    "        logits = m(inputs.to(DEV))[:, LIST_LEN+1:].reshape(-1, VOCAB) \n",
    "        loss = ce(logits, targets[:, LIST_LEN+1:].reshape(-1).to(DEV))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        if (step + 1) % 100 == 0:\n",
    "            acc = accuracy(m)\n",
    "            if acc > early_stop_acc:\n",
    "                print(f\"Early stopping at step {step + 1} with accuracy {acc:.2%} >= {early_stop_acc:.2%}\")\n",
    "                break\n",
    "            update_every = max(min(10_000, max_steps//20), 1000)\n",
    "            if verbose and (step+1) % update_every == 0:\n",
    "                print(f\"Step {step + 1}, Loss: {loss.item():.4f}, Accuracy: {acc:.2%}\")\n",
    "            if checkpoints and (step+1) % 50_000 == 0:\n",
    "                save_model(m, MODEL_PATH)\n",
    "            \n",
    "    print(f\"Final accuracy: {accuracy(m):.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea857e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 60,  44, 101, 100, 100],\n",
       "         [ 28,  90, 101, 100, 100],\n",
       "         [ 93,  99, 101, 100, 100],\n",
       "         [ 19,  17, 101, 100, 100],\n",
       "         [ 49,  19, 101, 100, 100]]),\n",
       " tensor([[ 60,  44, 101,  60,  44],\n",
       "         [ 28,  90, 101,  28,  90],\n",
       "         [ 93,  99, 101,  93,  99],\n",
       "         [ 19,  17, 101,  19,  17],\n",
       "         [ 49,  19, 101,  49,  19]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check train set\n",
    "train_ds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a29f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------- experiment grid ----------\n",
    "def make_name(d_model, n_layers, ln, use_bias, freeze_wv, freeze_wo):\n",
    "    parts = [\n",
    "        f\"d{d_model}\",\n",
    "        f\"{n_layers}L\",\n",
    "        (\"LN\" if ln else \"noLN\"),\n",
    "        (\"Bias\" if use_bias else \"noBias\"),\n",
    "        (\"fWV\" if freeze_wv else \"uWV\"), # freeze / unfreeze\n",
    "        (\"fWO\" if freeze_wo else \"uWO\"),\n",
    "    ]\n",
    "    return \"_\".join(parts)\n",
    "\n",
    "specs = [\n",
    "    # {'name': 'd256', 'd_model': 256},\n",
    "    # {'name': 'd128', 'd_model': 128, 'weight_decay': 1.0},\n",
    "    # {'name': 'd64', 'd_model': 64},\n",
    "    \n",
    "    # {'name': 'd32', 'd_model': 32},\n",
    "    # {'name': 'd32_ln_bias', 'd_model': 32, 'ln': True, 'use_bias': True},\n",
    "    # {'name': 'd32_noLN', 'd_model': 32, 'ln': False, 'use_bias': True},\n",
    "    # {'name': 'd32_noBias', 'd_model': 32, 'ln': True, 'use_bias': False},\n",
    "    # {'name': 'd32_noLNnoBias', 'd_model': 32, 'ln': False, 'use_bias': False},\n",
    "    # {'name': 'd32_fwo', 'd_model': 32, 'freeze_wo': True},\n",
    "    # {'name': 'd32_unfwo', 'd_model': 32, 'freeze_wo': False},\n",
    "\n",
    "    # {'name': 'd16', 'd_model': 16},\n",
    "    # {'name': 'd16_ln_bias', 'd_model': 16, 'ln': True, 'use_bias': True},\n",
    "    # {'name': 'd16_noLN', 'd_model': 16, 'ln': False, 'use_bias': True},\n",
    "    # {'name': 'd16_noBias', 'd_model': 16, 'ln': True, 'use_bias': False},\n",
    "    # {'name': 'd16_noLNnoBias', 'd_model': 16, 'ln': False, 'use_bias': False},\n",
    "    # {'name': 'd16_fwo', 'd_model': 16, 'freeze_wo': True},\n",
    "    # {'name': 'd16_unfwo', 'd_model': 16, 'freeze_wo': False},\n",
    "\n",
    "    # {'name': 'd8', 'd_model': 8},\n",
    "    # {'name': 'd8_ln_bias', 'd_model': 8, 'ln': True, 'use_bias': True},\n",
    "    # {'name': 'd8_noLN', 'd_model': 8, 'ln': False, 'use_bias': True},\n",
    "    # {'name': 'd8_noBias', 'd_model': 8, 'ln': True, 'use_bias': False},\n",
    "    # {'name': 'd8_noLNnoBias', 'd_model': 8, 'ln': False, 'use_bias': False},\n",
    "    # {'name': 'd8_fwo', 'd_model': 8, 'freeze_wo': True},\n",
    "    # {'name': 'd8_unfwo', 'd_model': 8, 'freeze_wo': False},\n",
    "\n",
    "    # {'name': 'd4', 'd_model': 4},\n",
    "]\n",
    "\n",
    "from itertools import product\n",
    "# specs = []\n",
    "# d_model = 128\n",
    "# for n_layers, ln, use_bias, freeze_wv, freeze_wo in product(\n",
    "#     [2, 3],            # layers\n",
    "#     [False, True],     # ln\n",
    "#     [False, True],     # use_bias\n",
    "#     [False, True],     # freeze_wv\n",
    "#     [False, True],     # freeze_wo\n",
    "# ):\n",
    "#     specs.append({\n",
    "#         \"name\": make_name(d_model, n_layers, ln, use_bias, freeze_wv, freeze_wo),\n",
    "#         \"d_model\": d_model,\n",
    "#         \"n_layers\": n_layers,\n",
    "#         \"ln\": ln,\n",
    "#         \"use_bias\": use_bias,\n",
    "#         \"freeze_wv\": freeze_wv,\n",
    "#         \"freeze_wo\": freeze_wo,\n",
    "#     })\n",
    "\n",
    "# -----------------------\n",
    "rows = []\n",
    "for spec in specs:\n",
    "    # Create a full spec by starting with defaults and updating with the current spec\n",
    "    full_spec = {\n",
    "        'n_layers': N_LAYER,\n",
    "        'n_heads': N_HEAD,\n",
    "        'd_model': D_MODEL,\n",
    "        'ln': USE_LN,\n",
    "        'bias': USE_BIAS,\n",
    "        'freeze_wv': FREEZE_WV,\n",
    "        'freeze_wo': FREEZE_WO,\n",
    "        'lr': LEARNING_RATE,\n",
    "        'weight_decay': WEIGHT_DECAY,\n",
    "    }\n",
    "    full_spec.update(spec) # Overwrite defaults with provided spec values\n",
    "\n",
    "    print(f\"--- Training model: {full_spec['name']} ---\")\n",
    "    model = make_model(\n",
    "        n_layers=full_spec['n_layers'],\n",
    "        n_heads=full_spec['n_heads'],\n",
    "        d_model=full_spec['d_model'], \n",
    "        ln=full_spec['ln'],\n",
    "        use_bias=full_spec['bias'],\n",
    "        freeze_wv=full_spec['freeze_wv'],\n",
    "        freeze_wo=full_spec['freeze_wo'],\n",
    "    )\n",
    "\n",
    "    train(model, max_steps=50_000, lr=full_spec['lr'], weight_decay=full_spec['weight_decay'], verbose=True)\n",
    "    \n",
    "    # Add all spec parameters to the results\n",
    "    result = full_spec.copy()\n",
    "    result['val_acc'] = round(accuracy(model), 4)\n",
    "    rows.append(result)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Move 'name' column to the front for better readability\n",
    "if 'name' in df.columns:\n",
    "    cols = ['name'] + [col for col in df.columns if col != 'name']\n",
    "    df = df[cols]\n",
    "\n",
    "print(df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d7ce1",
   "metadata": {},
   "source": [
    "**RESULTS**\n",
    "\n",
    "| name                        |   n_layers |   n_heads |   d_model | ln    | use_bias   | freeze_wv   | freeze_wo   |   weight_decay |   val_acc |\n",
    "|:----------------------------|-----------:|----------:|----------:|:------|:-----------|:------------|:------------|---------------:|----------:|\n",
    "| d128_2L_noLN_noBias_uWV_uWO |          2 |         1 |       128 | False | False      | False       | False       |           0.01 |    0.4625 |\n",
    "| d128_2L_noLN_noBias_uWV_fWO |          2 |         1 |       128 | False | False      | False       | True        |           0.01 |    0.4895 |\n",
    "| d128_2L_noLN_noBias_fWV_uWO |          2 |         1 |       128 | False | False      | True        | False       |           0.01 |    0.463  |\n",
    "| d128_2L_noLN_noBias_fWV_fWO |          2 |         1 |       128 | False | False      | True        | True        |           0.01 |    0.9173 |\n",
    "| d128_2L_noLN_Bias_uWV_uWO   |          2 |         1 |       128 | False | True       | False       | False       |           0.01 |    0.868  |\n",
    "| d128_2L_noLN_Bias_uWV_fWO   |          2 |         1 |       128 | False | True       | False       | True        |           0.01 |    0.8945 |\n",
    "| d128_2L_noLN_Bias_fWV_uWO   |          2 |         1 |       128 | False | True       | True        | False       |           0.01 |    0.4645 |\n",
    "| d128_2L_noLN_Bias_fWV_fWO   |          2 |         1 |       128 | False | True       | True        | True        |           0.01 |    0.9183 |\n",
    "| d128_2L_LN_noBias_uWV_uWO   |          2 |         1 |       128 | True  | False      | False       | False       |           0.01 |    0.4743 |\n",
    "| d128_2L_LN_noBias_uWV_fWO   |          2 |         1 |       128 | True  | False      | False       | True        |           0.01 |    0.4607 |\n",
    "| d128_2L_LN_noBias_fWV_uWO   |          2 |         1 |       128 | True  | False      | True        | False       |           0.01 |    0.4632 |\n",
    "| d128_2L_LN_noBias_fWV_fWO   |          2 |         1 |       128 | True  | False      | True        | True        |           0.01 |    0.4485 |\n",
    "| d128_2L_LN_Bias_uWV_uWO     |          2 |         1 |       128 | True  | True       | False       | False       |           0.01 |    0.4733 |\n",
    "| d128_2L_LN_Bias_uWV_fWO     |          2 |         1 |       128 | True  | True       | False       | True        |           0.01 |    0.4647 |\n",
    "| d128_2L_LN_Bias_fWV_uWO     |          2 |         1 |       128 | True  | True       | True        | False       |           0.01 |    0.4755 |\n",
    "| d128_2L_LN_Bias_fWV_fWO     |          2 |         1 |       128 | True  | True       | True        | True        |           0.01 |    0.4602 |\n",
    "\n",
    "| name   |   n_layers |   n_heads |   d_model | ln    | use_bias   | freeze_wv   | freeze_wo   |   weight_decay |   val_acc |\n",
    "|:-------|-----------:|----------:|----------:|:------|:-----------|:------------|:------------|---------------:|----------:|\n",
    "| d256   |          2 |         1 |       256 | False | False  | True        | True        |           0.01 |    0.8697 |\n",
    "| d128   |          2 |         1 |       128 | False | False      | True        | True        |           0.01 |    0.9038 |\n",
    "| d64    |          2 |         1 |        64 | False | False      | True        | True        |           0.01 |    0.6836 |\n",
    "| d32    |          2 |         1 |        32 | False | False      | True        | True        |           0.01 |    0.4278 |\n",
    "| d16    |          2 |         1 |        16 | False | False      | True        | True        |           0.01 |    0.4497 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0e08dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff73186811d549f7b06f86a9de94e26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, Loss: 0.6790, Accuracy: 45.02%\n",
      "Step 5000, Loss: 0.6872, Accuracy: 44.73%\n",
      "Step 7500, Loss: 0.6986, Accuracy: 43.75%\n",
      "Step 10000, Loss: 0.6884, Accuracy: 43.80%\n",
      "Step 12500, Loss: 0.6805, Accuracy: 43.33%\n",
      "Step 15000, Loss: 0.6802, Accuracy: 42.58%\n",
      "Step 17500, Loss: 0.6889, Accuracy: 42.50%\n",
      "Step 20000, Loss: 0.6943, Accuracy: 43.20%\n",
      "Step 22500, Loss: 0.6754, Accuracy: 42.08%\n",
      "Step 25000, Loss: 0.6813, Accuracy: 41.90%\n",
      "Step 27500, Loss: 0.3778, Accuracy: 82.23%\n",
      "Step 30000, Loss: 0.2334, Accuracy: 86.98%\n",
      "Step 32500, Loss: 0.1475, Accuracy: 88.65%\n",
      "Step 35000, Loss: 0.1503, Accuracy: 90.03%\n",
      "Step 37500, Loss: 0.1251, Accuracy: 89.90%\n",
      "Step 40000, Loss: 0.1291, Accuracy: 90.40%\n",
      "Step 42500, Loss: 0.1082, Accuracy: 91.05%\n",
      "Step 45000, Loss: 0.1254, Accuracy: 91.05%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m model = make_model()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAX_TRAIN_STEPS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUSE_CHECKPOINTING\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m save_model(model, MODEL_PATH)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(m, max_steps, early_stop_acc, checkpoints, lr, weight_decay, verbose)\u001b[39m\n\u001b[32m     22\u001b[39m loss = ce(logits, targets[:, LIST_LEN+\u001b[32m1\u001b[39m:].reshape(-\u001b[32m1\u001b[39m).to(DEV))\n\u001b[32m     23\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m opt.zero_grad()\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (step + \u001b[32m1\u001b[39m) % \u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Mechinterp/list-comp/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:516\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    513\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Mechinterp/list-comp/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Mechinterp/list-comp/.venv/lib/python3.12/site-packages/torch/optim/adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Mechinterp/list-comp/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:149\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Mechinterp/list-comp/.venv/lib/python3.12/site-packages/torch/optim/adam.py:949\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Mechinterp/list-comp/.venv/lib/python3.12/site-packages/torch/optim/adam.py:533\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    531\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m         denom = (\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m / bias_correction2_sqrt).add_(eps)\n\u001b[32m    535\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    537\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# LOAD existing or train and SAVE new model\n",
    "load_existing = True  # Set to False to always train a new model\n",
    "\n",
    "if os.path.exists(MODEL_PATH) and load_existing:\n",
    "    model = load_model(MODEL_PATH, device=DEV)\n",
    "else:\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        MODEL_PATH = MODEL_PATH.replace(\".pt\", \"_new.pt\")\n",
    "        print(f\"Model path already exists. Saving new model to {MODEL_PATH}\")\n",
    "    print(\"Training model\")\n",
    "    model = make_model()\n",
    "    train(model, max_steps=MAX_TRAIN_STEPS, checkpoints=USE_CHECKPOINTING)\n",
    "    save_model(model, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456419a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Overview of Model Parameters ---\n",
      "Parameter Name                           | Shape                | Trainable \n",
      "--------------------------------------------------------------------------------\n",
      "embed.W_E                                | (102, 64)            | Yes       \n",
      "pos_embed.W_pos                          | (5, 64)              | Yes       \n",
      "blocks.0.attn.W_Q                        | (1, 64, 64)          | Yes       \n",
      "blocks.0.attn.W_K                        | (1, 64, 64)          | Yes       \n",
      "blocks.1.attn.W_Q                        | (1, 64, 64)          | Yes       \n",
      "blocks.1.attn.W_K                        | (1, 64, 64)          | Yes       \n",
      "unembed.W_U                              | (64, 102)            | Yes       \n",
      "--------------------------------------------------------------------------------\n",
      "Total parameters: 46758\n",
      "Trainable parameters: 29760\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Model Parameters Overview ---\n",
    "print(\"--- Overview of Model Parameters ---\")   \n",
    "total_params = 0\n",
    "trainable_params = 0\n",
    "\n",
    "# Use a formatted string for better alignment\n",
    "print(f\"{'Parameter Name':<40} | {'Shape':<20} | {'Trainable':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    shape_str = str(tuple(param.shape))\n",
    "    is_trainable = \"Yes\" if param.requires_grad else \"No\"\n",
    "    total_params += param.numel()\n",
    "\n",
    "    if not param.requires_grad:\n",
    "        continue\n",
    "    # Print only trainable parameters\n",
    "    print(f\"{name:<40} | {shape_str:<20} | {is_trainable:<10}\")\n",
    "    trainable_params += param.numel()\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a57f82e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
