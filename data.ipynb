{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "172b8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df394ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7e84d0214750>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIST_LEN = 2 # [d1, d2]\n",
    "SEQ_LEN = LIST_LEN * 2 + 1 # [d1, d2, SEP, o1, o2]\n",
    "NO_DUPES = True # whether to use the no-dupes test dataset (i.e. d1 != d2)\n",
    "\n",
    "N_DIGITS = 100\n",
    "DIGITS = list(range(N_DIGITS)) # 100 digits from 0 to 99\n",
    "PAD = N_DIGITS # special padding token\n",
    "SEP = N_DIGITS + 1 # special seperator token for the model to think about the input (+1 to avoid confusion with the last digit)\n",
    "VOCAB = len(DIGITS) + 2  # + the special tokens\n",
    "\n",
    "# For backward compatibility with older versions\n",
    "USE_PAD = True # whether to use the PAD token in the input sequences (or just SEP)\n",
    "if not USE_PAD:\n",
    "    VOCAB -= 1  # -1 for the PAD token    \n",
    "\n",
    "D_MODEL = 16\n",
    "N_HEAD = 1 # 1\n",
    "N_LAYER = 3 # 2\n",
    "USE_LN = False # use layer norm in model\n",
    "USE_BIAS = False # use bias in model\n",
    "FREEZE_WV = True # no value matrix in attn \n",
    "FREEZE_WO = True # no output matrix in attn (i.e. attn head can only copy inputs to outputs)\n",
    "WEIGHT_DECAY = 0.01 # default 0.01\n",
    "\n",
    "TRAIN_SPLIT = 0.8 # 80% train, 20% test\n",
    "\n",
    "DEV = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "device = DEV\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fefaa0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    # Create all possible combinations of digits\n",
    "    all_data = list(itertools.product(DIGITS, repeat=LIST_LEN))\n",
    "    n_data = len(all_data)\n",
    "    all_data = torch.tensor(all_data, dtype=torch.int64)\n",
    "    if NO_DUPES:\n",
    "        # Filter out combinations where d1 == d2\n",
    "        all_data = all_data[all_data[:, 0] != all_data[:, 1]]\n",
    "        n_data = len(all_data)\n",
    "\n",
    "    # Create sequences of the form [d1, d2, SEP, d1, d2]\n",
    "    all_targets = torch.full((n_data, SEQ_LEN), SEP)\n",
    "    all_targets[:, :LIST_LEN] = all_data\n",
    "    all_targets[:, LIST_LEN+1:] = all_data\n",
    "\n",
    "    # Create input sequences of the form [d1, d2, SEP, PAD, PAD]\n",
    "    all_inputs = all_targets.clone()\n",
    "    all_inputs[:, LIST_LEN+1:] = PAD\n",
    "\n",
    "    # Shuffle the dataset (inputs and targets together)\n",
    "    perm = torch.randperm(n_data)\n",
    "    all_inputs = all_inputs[perm]\n",
    "    all_targets = all_targets[perm]\n",
    "\n",
    "    train_ds = TensorDataset(all_inputs[:int(TRAIN_SPLIT*n_data)], all_targets[:int(TRAIN_SPLIT*n_data)])  # 80% for training\n",
    "    val_ds = TensorDataset(all_inputs[int(TRAIN_SPLIT*n_data):], all_targets[int(TRAIN_SPLIT*n_data):])  # 20% for validation\n",
    "        \n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e797dde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to data/listlen2_digits100_dupes.pt\n",
      "Train dataset size: 8000\n",
      "Validation dataset size: 2000\n",
      "Input example: tensor([ 60,  44, 101, 100, 100])\n",
      "Target example: tensor([ 60,  44, 101,  60,  44])\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = f\"listlen{LIST_LEN}_digits{N_DIGITS}_{'nodupes' if NO_DUPES else 'dupes'}\"\n",
    "DATASET_PATH = f\"data/{DATASET_NAME}.pt\"\n",
    "\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    raise FileExistsError(f\"{DATASET_PATH} already exists. Please delete it or change the dataset name.\")\n",
    "\n",
    "train_ds, val_ds = get_dataset()\n",
    "\n",
    "torch.save({\n",
    "    'train': train_ds,\n",
    "    'val': val_ds\n",
    "}, DATASET_PATH)\n",
    "\n",
    "print(f\"Dataset saved to {DATASET_PATH}\")\n",
    "print(\"Train dataset size:\", len(train_ds))\n",
    "print(\"Validation dataset size:\", len(val_ds))\n",
    "print(\"Input example:\", train_ds[0][0])\n",
    "print(\"Target example:\", train_ds[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
